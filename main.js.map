{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///external \"tslib\"","webpack:///./libs/article-parser/src/lib/correlation-score/correlation-constants.ts","webpack:///external \"express\"","webpack:///external \"natural\"","webpack:///external \"node-fetch\"","webpack:///./libs/word-explorer/src/index.ts","webpack:///external \"body-parser\"","webpack:///./libs/article-parser/src/index.ts","webpack:///./apps/api-express/src/app/daos/search.ts","webpack:///./libs/interfaces/src/lib/interfaces.ts","webpack:///./libs/scholars-scraper/src/lib/index.ts","webpack:///./libs/scholars-scraper/src/lib/scraper/scholars-scraper.ts","webpack:///./libs/scraper/src/lib/scraper.ts","webpack:///./libs/scholars-scraper/src/lib/parsers/scholars-parser.ts","webpack:///./libs/word-explorer/src/lib/word-explorer.ts","webpack:///./libs/article-parser/src/lib/index.ts","webpack:///./libs/article-parser/src/lib/parser/index.ts","webpack:///./libs/article-parser/src/lib/parser/ebi-parser.ts","webpack:///./libs/article-parser/src/lib/correlation-score/correlation-score.ts","webpack:///./apps/api-express/src/app/app.ts","webpack:///./apps/api-express/src/app/controllers/index.ts","webpack:///./apps/api-express/src/app/controllers/search.ts","webpack:///./apps/api-express/src/app/daos/index.ts","webpack:///./libs/interfaces/src/index.ts","webpack:///./libs/scholars-scraper/src/index.ts","webpack:///./libs/scraper/src/index.ts","webpack:///./libs/scholars-scraper/src/lib/parsers/index.ts","webpack:///external \"xml2js\"","webpack:///external \"util\"","webpack:///external \"wordnet\"","webpack:///external \"cheerio\"","webpack:///./apps/api-express/src/main.ts"],"names":[],"mappings":";QAAA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;;QAEA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;;;QAGA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;QACA,0CAA0C,gCAAgC;QAC1E;QACA;;QAEA;QACA;QACA;QACA,wDAAwD,kBAAkB;QAC1E;QACA,iDAAiD,cAAc;QAC/D;;QAEA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA,yCAAyC,iCAAiC;QAC1E,gHAAgH,mBAAmB,EAAE;QACrI;QACA;;QAEA;QACA;QACA;QACA,2BAA2B,0BAA0B,EAAE;QACvD,iCAAiC,eAAe;QAChD;QACA;QACA;;QAEA;QACA,sDAAsD,+DAA+D;;QAErH;QACA;;;QAGA;QACA;;;;;;;AClFA,kC;;;;;;;ACAA;AAAA;AAAO,MAAM,kBAAkB,GAAG;IAChC,8DAA8D;IAC9D,6DAA6D;IAC7D,yBAAyB,EAAE,CAAC;IAC5B,qBAAqB,EAAE,GAAG;IAC1B,cAAc,EAAE,CAAC;IACjB,sBAAsB,EAAE,CAAC;IACzB,6BAA6B,EAAE,GAAG;CACnC,CAAC;AAEK,MAAM,OAAO,GAAG;IACrB,mBAAmB,EAAE,IAAI;IACzB,0BAA0B,EAAE,EAAE;CAC/B,CAAC;;;;;;;ACbF,oC;;;;;;ACAA,oC;;;;;;ACAA,uC;;;;;;;ACAA;AAAA;AAAA;AAAoC;;;;;;;ACApC,wC;;;;;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAsB;;;;;;;;;;;;;;;ACKY;AACkC;AACN;AAEvD,SAAe,gBAAgB,CACpC,KAAa,EACb,IAGC;;QAED,+DAA+D;QAC/D,MAAM,YAAY,GAAG,MAAM,iGAAkB,CAC3C,KAAK;QACL,sGAAsG;QACtG,KAAK,EACL,KAAI,aAAJ,IAAI,uBAAJ,IAAI,CAAE,gBAAgB,KAAI,CAAC,CAC5B,CAAC;QACF,MAAM,aAAa,GAA6B,YAAY,CAAC,GAAG,CAC9D,CAAO,WAAW,EAAE,EAAE,CAAC;YACrB,MAAM,gBAAgB,GAAkB,MAAM,oFAA6B,CACzE,WAAW,EACX,8EAAuB,CACxB,CAAC;YACF,OAAO,gBAAgB,CAAC;QAC1B,CAAC,EACF,CAAC;QACF,MAAM,oBAAoB,GAAoB,MAAM,OAAO,CAAC,GAAG,CAC7D,aAAa,CACd,CAAC;QACF,MAAM,uBAAuB,GAAuC,EAAE,CAAC;QACvE,oBAAoB,CAAC,OAAO,CAAC,CAAC,OAAO,EAAE,EAAE;YACvC,MAAM,oBAAoB,GAAuC,OAAO,CAAC,UAAU,CAAC,GAAG,CACrF,CAAC,SAAiC,EAAE,EAAE;gBACpC,uBACE,IAAI,EAAE,OAAO,CAAC,IAAI;oBAClB,+FAA+F;oBAC/F,YAAY,EAAE,6FAA4B,CAAC,aAAa,IACrD,SAAS,EACZ;YACJ,CAAC,CACF,CAAC;YACF,uBAAuB,CAAC,IAAI,CAAC,GAAG,oBAAoB,CAAC,CAAC;QACxD,CAAC,CAAC,CAAC;QACH,2BAA2B;QAC3B,uBAAuB,CAAC,IAAI,CAC1B,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,gBAAgB,GAAG,CAAC,CAAC,gBAAgB,CAClD,CAAC;QACF,OAAO,uBAAuB,CAAC,KAAK,CAClC,CAAC,EACD,KAAI,aAAJ,IAAI,uBAAJ,IAAI,CAAE,qBAAqB,KAAI,uBAAuB,CAAC,MAAM,CAC9D,CAAC;IACJ,CAAC;CAAA;;;;;;;;ACzDD;AAAA,IAAY,4BAIX;AAJD,WAAY,4BAA4B;IACtC,yCAAS;IACT,wCAAQ;IACR,oDAAoB;AACtB,CAAC,EAJW,4BAA4B,KAA5B,4BAA4B,QAIvC;;;;;;;;ACJD;AAAA;AAAA;AAA2C;;;;;;;;;;;;;;;ACK3C,8DAA8D;AACd;AACV;AACoB;AAE1D;;;GAGG;AACH,SAAS,iBAAiB,CACxB,QAAgB,EAChB,QAAgB,EAChB,QAAgB,EAChB,OAAO,GAAG,IAAI;IAEd,OAAO,SAAS,CACd,iEAAiE,QAAQ,IAAI,QAAQ,YAAY,OAAO,aAAa,QAAQ,EAAE,CAChI,CAAC;AACJ,CAAC;AAED;;;;GAIG;AACI,SAAe,kBAAkB,CACtC,QAAgB,EAChB,cAAsB,EACtB,QAAQ,GAAG,EAAE;;QAEb,MAAM,QAAQ,GAAG,iBAAiB,CAAC,QAAQ,EAAE,cAAc,EAAE,QAAQ,CAAC,CAAC;QACvE,MAAM,gBAAgB,GAAG,MAAM,uFAAW,CAAC,QAAQ,CAAC,CAAC;QACrD,MAAM,aAAa,GAAG,IAAI,qEAAO,CAAoB,+DAAsB,EAAE;YAC3E,GAAG,EAAE,QAAQ;YACb,GAAG,EAAE;gBACH,cAAc,EAAE,cAAc;gBAC9B,QAAQ,EAAE,QAAQ;gBAClB,gBAAgB;aACjB;SACY,CAAC,CAAC;QAEjB,MAAM,YAAY,GAAG,MAAM,aAAa,CAAC,GAAG,EAAE,CAAC;QAC/C,OAAO,YAAY,CAAC;IACtB,CAAC;CAAA;;;;;;;;;;;;;;AC/C8B;AAG/B;;;;GAIG;AACI,MAAM,OAAO;IAGlB,YAAY,MAAoB,EAAE,GAAG,YAA0B;QAC7D,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;QACrB,IAAI,CAAC,YAAY,GAAG,YAAY,CAAC;IACnC,CAAC;IAED;;OAEG;IACG,aAAa,CAAC,GAAW;;YAC7B,MAAM,GAAG,GAAG,MAAM,iDAAK,CAAC,GAAG,CAAC,CAAC;YAC7B,OAAO,MAAM,GAAG,CAAC,IAAI,EAAE,CAAC;QAC1B,CAAC;KAAA;IAEK,oBAAoB,CAAC,GAAW,EAAE,IAAS;;YAC/C,OAAO,CAAC,IAAI,CAAC,cAAc,EAAE,GAAG,CAAC;YACjC,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC;YAC7C,OAAO,MAAM,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,EAAE,IAAI,CAAW,CAAC;QAC3D,CAAC;KAAA;IAED;;OAEG;IACU,GAAG;;YACd,mEAAmE;YACnE,MAAM,iBAAiB,GAAG,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAO,UAAU,EAAE,EAAE;gBACnE,aAAM,IAAI,CAAC,oBAAoB,CAAC,UAAU,CAAC,GAAG,EAAE;oBAC9C,GAAG,EAAE,UAAU,CAAC,GAAG;iBACpB,CAAC;cAAA,CACH,CAAC;YACF,MAAM,UAAU,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;YAExD,4DAA4D;YAC5D,+DAA+D;YAC/D,OAAO,UAAU,CAAC,IAAI,EAAE,CAAC;QAC3B,CAAC;KAAA;CACF;;;;;;;;;;;;;;;AC1C+B;AAC2B;AAE3D;;GAEG;AACI,MAAM,cAAc,GAA8B;IACvD,OAAO,EAAE,CAAO,GAAG,EAAE,IAAyB,EAAE,EAAE,CAAC;QACjD,IAAI,CAAC,IAAI,EAAE;YACT,MAAM,0CAA0C,CAAC;SAClD;QACD,MAAM,MAAM,GAAG,IAAI,6CAAY,EAAE,CAAC;QAClC,MAAM,OAAO,GAAG,MAAM,MAAM,CAAC,kBAAkB,CAAC,GAAG,CAAC,CAAC;QACrD,MAAM,UAAU,GAAG,OAAO,CAAC,eAAe,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC;QAChE,MAAM,sBAAsB,GAAG,MAAM,+EAAwB,CAAC,IAAI,CAAC,GAAG,CAAC,cAAc,CAAC,CAAC;QACvF,MAAM,WAAW,GAAwB,UAAU,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,EAAE;YAC9D,OAAO;gBACL,EAAE,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC;gBACb,KAAK,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC;gBACnB,uBAAuB,EAAE,oDAAoD,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,cAAc;gBACpG,cAAc,EAAE,IAAI,CAAC,GAAG,CAAC,cAAc;gBACvC,QAAQ,EAAE,IAAI,CAAC,GAAG,CAAC,QAAQ;gBAC3B,gBAAgB,EAAE,IAAI,CAAC,GAAG,CAAC,gBAAgB;gBAC3C,sBAAsB,EAAE,sBAAsB;aAC/C,CAAC;QACJ,CAAC,CAAC,CAAC;QACH,OAAO,WAAW,CAAC;IACrB,CAAC;CACF,CAAC;;;;;;;;;;;;;;;;;;ACjC2B;AACM;AACA;AAEnC,MAAM,aAAa,GAAG,8CAAc,CAAC,8CAAc,CAAC,CAAC;AAE9C,SAAe,WAAW,CAAC,IAAY;;QAC5C,qBAAqB;QACrB,MAAM,oBAAoB,GAA0B,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,GAAG,CACrE,CAAO,cAAc,EAAuB,EAAE,CAAC;YAC7C,IAAI;gBACF,OAAO,CACL,MAAM,aAAa,CAAC,qDAAqB,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC,CAChE,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;aACzD;YAAC,OAAO,CAAC,EAAE;gBACV,OAAO,CAAC,KAAK,CACX,yCAAyC,EACzC,cAAc,EACd,CAAC,CACF,CAAC;gBACF,OAAO,CAAC,EAAE,CAAC,CAAC;aACb;QACH,CAAC,EACF,CAAC;QACF,MAAM,eAAe,GAAiB,MAAM,OAAO,CAAC,GAAG,CAAC,oBAAoB,CAAC,CAAC;QAC9E,kDAAkD;QAClD,MAAM,YAAY,GAAG,eAAe;aACjC,IAAI,CAAC,QAAQ,CAAC;aACd,MAAM,CAAC,CAAC,OAAO,EAAE,EAAE,CAAC,OAAO,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,CAAC;QAC3D,IAAI,CAAC,YAAY,EAAE;YACjB,OAAO,EAAE,CAAC;SACX;QACD,OAAO,CAAC,IAAI,CAAC,6BAA6B,EAAE,IAAI,EAAE,YAAY,CAAC,CAAC;QAChE,OAAO,YAAY,CAAC;IACtB,CAAC;CAAA;AAED,wCAAwC;;;;;;;;ACpCxC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAyB;AAC6B;;;;;;;;ACDtD;AAAA;AAAA;AAA6B;;;;;;;;;;;;;;ACMM;AAEnC;;GAEG;AACI,MAAM,SAAS,GAA0B;IAC9C,OAAO,EAAE,CAAO,GAAW,EAAE,IAAuB,EAAE,EAAE,CAAC;QACvD,IAAI,EAAC,IAAI,aAAJ,IAAI,uBAAJ,IAAI,CAAE,iBAAiB,GAAE;YAC5B,MAAM,+BAA+B,CAAC;SACvC;QACD,MAAM,CAAC,GAAG,4CAAY,CAAC,GAAG,CAAC,CAAC;QAC5B,MAAM,cAAc,GAAa,CAAC,CAAC,GAAG,CAAC;aACpC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC;aAC5B,GAAG,EAAE,CAAC;QACT,MAAM,UAAU,GAA6B,cAAc,CAAC,GAAG,CAC7D,CAAC,aAAa,EAAE,EAAE,CAChB,IAAI,CAAC,mBAAmB,CACtB,aAAa,EACb,IAAI,CAAC,iBAAiB,CAAC,QAAQ,EAC/B,IAAI,CAAC,iBAAiB,CAAC,cAAc,EACrC,IAAI,CAAC,iBAAiB,CAAC,gBAAgB,EACvC,IAAI,CAAC,iBAAiB,CAAC,sBAAsB,CAC9C,CACJ,CAAC;QACF,MAAM,OAAO,GAAkB;YAC7B,IAAI,EAAE,IAAI,CAAC,iBAAiB;YAC5B,UAAU;SACX,CAAC;QACF,OAAO,OAAO,CAAC;IACjB,CAAC;CACF,CAAC;;;;;;;;;;;;;;;;;AC7BkC;AACkC;AACnC;AAEnC,MAAM,SAAS,GAAG,IAAI,qDAAqB,EAAE,CAAC;AAE9C,SAAe,eAAe,CAAC,GAAW;;QACxC,MAAM,GAAG,GAAG,MAAM,uCAAK,CAAC,GAAG,CAAC,CAAC;QAC7B,OAAO,MAAM,GAAG,CAAC,IAAI,EAAE,CAAC;IAC1B,CAAC;CAAA;AAED;;GAEG;AACH,SAAS,iBAAiB,CAAC,IAAY,EAAE,SAAiB;IACxD,MAAM,kBAAkB,GAAG,SAAS,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC;IACzD,MAAM,gBAAgB,GAAG,kBAAkB,CAAC,MAAM,CAChD,CAAC,IAAY,EAAE,aAAa,EAAE,EAAE;QAC9B,uDAAuD;QACvD,MAAM,QAAQ,GAAG,2DAA2B,CAAC,IAAI,EAAE,aAAa,CAAC,CAAC;QAClE,OAAO,IAAI,GAAG,CAAC,QAAQ,GAAG,sEAAO,CAAC,mBAAmB,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACxE,CAAC,EACD,CAAC,CACF,CAAC;IACF,OAAO,gBAAgB,CAAC;AAC1B,CAAC;AAED,SAAS,kBAAkB,CAAC,KAAe,EAAE,SAAiB;IAC5D,OAAO,KAAK;SACT,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,iBAAiB,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC;SACjD,MAAM,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,EAAE,CAAC,KAAK,GAAG,KAAK,EAAE,CAAC,CAAC,CAAC;AAChD,CAAC;AAED;;;;GAIG;AACH,SAAS,YAAY,CACnB,UAAkB,EAClB,kBAA0B,EAC1B,iBAAyB,EACzB,yBAAiC,EACjC,kBAA0B;IAE1B,MAAM,WAAW,GAAG,UAAU,GAAG,iFAAkB,CAAC,cAAc,CAAC;IACnE,MAAM,mBAAmB,GACvB,kBAAkB,GAAG,iFAAkB,CAAC,sBAAsB,CAAC;IACjE,MAAM,kBAAkB,GACtB,iBAAiB,GAAG,iFAAkB,CAAC,qBAAqB,CAAC;IAC/D,MAAM,0BAA0B,GAC9B,yBAAyB;QACzB,iFAAkB,CAAC,6BAA6B,CAAC;IACnD,MAAM,UAAU,GACd,UAAU;QACV,kBAAkB;QAClB,iFAAkB,CAAC,yBAAyB,CAAC;IAC/C,6EAA6E;IAC7E,OAAO,CACL,WAAW;QACX,mBAAmB;QACnB,UAAU;QACV,kBAAkB;QAClB,0BAA0B,CAC3B,CAAC;AACJ,CAAC;AAED,SAAS,UAAU,CAAC,KAAa;IAC/B,OAAO,qDAAqB,CAAC,eAAe,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;AAChE,CAAC;AAED,SAAS,iCAAiC,CACxC,SAAiB,EACjB,QAAgB,EAChB,cAAsB,EACtB,gBAA0B,EAC1B,sBAAgC;IAEhC,MAAM,YAAY,GAAG,UAAU,CAAC,QAAQ,CAAC,CAAC;IAC1C,MAAM,gBAAgB,GAAG,UAAU,CAAC,SAAS,CAAC,CAAC;IAC/C,MAAM,kBAAkB,GAAG,UAAU,CAAC,cAAc,CAAC,CAAC;IACtD,MAAM,iBAAiB,GAAG,kBAAkB,CAC1C,gBAAgB,EAChB,gBAAgB,CACjB,CAAC;IACF,MAAM,yBAAyB,GAAG,kBAAkB,CAClD,sBAAsB,EACtB,gBAAgB,CACjB,CAAC;IAEF,MAAM,gBAAgB,GAAG,YAAY,CACnC,iBAAiB,CAAC,YAAY,EAAE,gBAAgB,CAAC,EACjD,iBAAiB,CAAC,kBAAkB,EAAE,gBAAgB,CAAC,EACvD,iBAAiB,EACjB,yBAAyB,EACzB,SAAS,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,MAAM,CAC5B,CAAC;IACF,OAAO;QACL,IAAI,EAAE,SAAS;QACf,gBAAgB;KACjB,CAAC;AACJ,CAAC;AAED;;;;GAIG;AACH,SAAS,oCAAoC,CAC3C,SAAiB,EACjB,QAAgB,EAChB,cAAsB,EACtB,gBAA0B,EAC1B,sBAAgC,EAChC,qBAAqB,GAAG,sEAAO,CAAC,0BAA0B;IAE1D,SAAS,6BAA6B,CAAC,CAAS,EAAE,CAAS;QACzD,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC;IACrC,CAAC;IACD,MAAM,SAAS,GAAG,SAAS,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;IACvC,yCAAyC;IACzC,IAAI,CAAC,SAAS,CAAC,SAAS,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE;QACpC,SAAS,CAAC,GAAG,EAAE,CAAC;KACjB;IACD,MAAM,SAAS,GAAG,iCAAiC,CACjD,SAAS,EACT,QAAQ,EACR,cAAc,EACd,gBAAgB,EAChB,sBAAsB,CACvB,CAAC,gBAAgB,CAAC;IACnB,IAAI,YAAY,GAAG,SAAS,CAAC;IAC7B,IAAI,OAAO,GAAG,CAAC,CAAC;IAChB,IAAI,oBAAoB,GAAG,SAAS,CAAC,MAAM,CAAC;IAC5C,mEAAmE;IACnE,2FAA2F;IAC3F,OACE,6BAA6B,CAAC,SAAS,EAAE,YAAY,CAAC;QACpD,qBAAqB,GAAG,CAAC;QAC3B,OAAO,IAAI,oBAAoB,EAC/B;QACA,YAAY,GAAG,iCAAiC,CAC9C,SAAS,CAAC,KAAK,CAAC,OAAO,EAAE,oBAAoB,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EACxD,QAAQ,EACR,cAAc,EACd,gBAAgB,EAChB,sBAAsB,CACvB,CAAC,gBAAgB,CAAC;QACnB,OAAO,EAAE,CAAC;KACX;IACD,6DAA6D;IAC7D,+EAA+E;IAC/E,OACE,6BAA6B,CAAC,SAAS,EAAE,YAAY,CAAC;QACpD,qBAAqB;QACvB,OAAO,IAAI,oBAAoB,EAC/B;QACA,YAAY,GAAG,iCAAiC,CAC9C,SAAS,CAAC,KAAK,CAAC,OAAO,EAAE,oBAAoB,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EACxD,QAAQ,EACR,cAAc,EACd,gBAAgB,EAChB,sBAAsB,CACvB,CAAC,gBAAgB,CAAC;QACnB,oBAAoB,EAAE,CAAC;KACxB;IACD,kFAAkF;IAClF,0FAA0F;IAC1F,gBAAgB;IAChB,oBAAoB;QAClB,oBAAoB,GAAG,SAAS,CAAC,MAAM;YACrC,CAAC,CAAC,oBAAoB,GAAG,CAAC;YAC1B,CAAC,CAAC,oBAAoB,CAAC;IAC3B,OAAO;QACL,gBAAgB,EAAE,YAAY;QAC9B,IAAI,EAAE,SAAS,CAAC,KAAK,CAAC,OAAO,EAAE,oBAAoB,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC;KAC/D,CAAC;AACJ,CAAC;AAEM,SAAe,eAAe,CACnC,WAA8B,EAC9B,MAA6B;;QAE7B,MAAM,QAAQ,GAAG,MAAM,eAAe,CAAC,WAAW,CAAC,uBAAuB,CAAC,CAAC;QAC5E,OAAO,CAAC,IAAI,CACV,sBAAsB,WAAW,CAAC,QAAQ,QAAQ,WAAW,CAAC,cAAc,aAAa,WAAW,CAAC,uBAAuB,EAAE,CAC/H,CAAC;QACF,wFAAwF;QACxF,OAAO,CAAC,MAAM,MAAM,CAAC,OAAO,CAAC,QAAQ,EAAE;YACrC,iBAAiB,EAAE,WAAW;YAC9B,QAAQ,EAAE,WAAW,CAAC,QAAQ;YAC9B,cAAc,EAAE,WAAW,CAAC,cAAc;YAC1C,mBAAmB,EAAE,oCAAoC;SACtC,CAAC,CAAkB,CAAC;IAC3C,CAAC;CAAA;;;;;;;;ACzMD;AAAA;AAAA;AAAA;AAAA;AAAmC;AACO;AACP;AAEnC,MAAM,GAAG,GAAG,oCAAO,EAAE,CAAC;AACtB,GAAG,CAAC,GAAG,CAAC,gDAAe,EAAE,CAAC,CAAC;AAC3B,GAAG,CAAC,GAAG,CAAC,sDAAqB,CAAC,EAAE,QAAQ,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;AAEnD,GAAG,CAAC,GAAG,CAAC,MAAM,EAAE,4DAAM,CAAC,CAAC;AAET,4DAAG,EAAC;;;;;;;;ACVnB;AAAA;AAAA;AAAmC;AACC;AAEpC,MAAM,MAAM,GAAG,8CAAc,EAAE,CAAC;AAEhC,MAAM,CAAC,GAAG,CAAC,SAAS,EAAE,uDAAY,CAAC,CAAC;AAErB,+DAAM,EAAC;;;;;;;;;;;;;;ACPa;AACQ;AAE3C,MAAM,MAAM,GAAG,8CAAc,EAAE,CAAC;AAEhC;;;;;GAKG;AACH,MAAM,CAAC,GAAG,CACR,GAAG,EACH,CACE,GAAoB,EACpB,GAAqB,EACrB,IAA0B,EAC1B,EAAE,CAAC;IACH,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAW,CAAC;IACpC,MAAM,OAAO,GAAG,MAAM,sEAAgB,CAAC,KAAK,EAAE;QAC5C,gBAAgB,EAAE,QAAQ,CAAC,GAAG,CAAC,KAAK,CAAC,gBAA0B,CAAC;QAChE,qBAAqB,EAAE,QAAQ,CAC7B,GAAG,CAAC,KAAK,CAAC,qBAA+B,CAC1C;KACF,CAAC,CAAC;IACH,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;AAChC,CAAC,EACF,CAAC;AAEa,+DAAM,EAAC;;;;;;;;AC7BtB;AAAA;AAAA;AAAwB;;;;;;;;ACAxB;AAAA;AAAA;AAAiC;;;;;;;;ACAjC;AAAA;AAAA;AAAsB;;;;;;;;ACAtB;AAAA;AAAA;AAA8B;;;;;;;;ACA9B;AAAA;AAAA;AAAkC;;;;;;;ACAlC,mC;;;;;;ACAA,iC;;;;;;ACAA,oC;;;;;;ACAA,oC;;;;;;;;;;;;;;ACAA;AAAA;AAA2B;AAE3B,MAAM,IAAI,GAAG,OAAO,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC;AACtC,MAAM,MAAM,GAAG,wDAAG,CAAC,MAAM,CAAC,IAAI,EAAE,GAAG,EAAE;IACnC,OAAO,CAAC,IAAI,CAAC,iCAAiC,IAAI,MAAM,CAAC,CAAC;AAC5D,CAAC,CAAC,CAAC;AACH,MAAM,CAAC,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,KAAK,CAAC,CAAC","file":"main.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 31);\n","module.exports = require(\"tslib\");","export const correlationWeights = {\n  // impact cross recommendation is high to place an emphasis on\n  // having both impact and recommendation within one paragraph\n  impactCrossRecommendation: 8,\n  impactSynonymWordFreq: 0.5,\n  impactWordFreq: 1,\n  recommendationWordFreq: 1,\n  recommendationSynonymWordFreq: 0.5,\n};\n\nexport const cutOffs = {\n  minimumWordDistance: 0.85,\n  maintainScoreWithinPercent: 10,\n};\n","module.exports = require(\"express\");","module.exports = require(\"natural\");","module.exports = require(\"node-fetch\");","export * from './lib/word-explorer';\n","module.exports = require(\"body-parser\");","export * from './lib';\n","import {\n  ParsedArticleParagraphStandalone,\n  ParsedArticle,\n  ParsedArticleParagraph,\n  ArticleParagraphBacksUpClaim,\n} from '@foodmedicine/interfaces';\nimport { runScholarsScraper } from '@foodmedicine/scholars-scraper';\nimport * as articleParser from '@foodmedicine/article-parser';\n\nexport async function findQueryResults(\n  query: string,\n  opts?: {\n    numberOfArticles?: number;\n    maxNumberOfParagraphs?: number;\n  }\n): Promise<ParsedArticleParagraphStandalone[]> {\n  // The query is the impact and the recommendation is left blank\n  const articleHeads = await runScholarsScraper(\n    query,\n    // TODO this is a temporary fix, removing the entire recommendation, impact abstraction should be done\n    query,\n    opts?.numberOfArticles || 5\n  );\n  const downloadProms: Promise<ParsedArticle>[] = articleHeads.map(\n    async (articleHead) => {\n      const evaluatedArticle: ParsedArticle = await articleParser.evaluateArticle(\n        articleHead,\n        articleParser.EbiParser\n      );\n      return evaluatedArticle;\n    }\n  );\n  const allEvaluatedArticles: ParsedArticle[] = await Promise.all(\n    downloadProms\n  );\n  const allParagraphsStandalone: ParsedArticleParagraphStandalone[] = [];\n  allEvaluatedArticles.forEach((article) => {\n    const standaloneParagraphs: ParsedArticleParagraphStandalone[] = article.paragraphs.map(\n      (paragraph: ParsedArticleParagraph) => {\n        return {\n          head: article.head,\n          // set default backsUpClaim to notApplicable. This later gets changed manually in the JSON file\n          backsUpClaim: ArticleParagraphBacksUpClaim.notApplicable,\n          ...paragraph,\n        };\n      }\n    );\n    allParagraphsStandalone.push(...standaloneParagraphs);\n  });\n  // sort in descending order\n  allParagraphsStandalone.sort(\n    (a, b) => b.correlationScore - a.correlationScore\n  );\n  return allParagraphsStandalone.slice(\n    0,\n    opts?.maxNumberOfParagraphs || allParagraphsStandalone.length\n  );\n}\n","export enum ArticleParagraphBacksUpClaim {\n  yes = 'y',\n  no = 'n',\n  notApplicable = 'na',\n}\n\ntype getCorrelationScoreFunction = (\n  paragraph: string,\n  impacted: string,\n  recommendation: string,\n  impactedSynonyms: string[],\n  recommendationSynonyms: string[]\n) => ParsedArticleParagraph;\n\nexport interface BaseParserOptions {\n  tag?: string;\n}\n\ninterface ArticleParserOptions extends BaseParserOptions {\n  getCorrelationScore: getCorrelationScoreFunction;\n}\n\nexport interface EbiParserOptions extends ArticleParserOptions {\n  parsedArticleHead: ParsedArticleHead;\n}\n\ninterface RecommendationInfo {\n  filename?: string;\n  recommendation: string;\n}\n\nexport interface HealthRemedies {\n  impacted: string;\n  recommendations: RecommendationInfo[];\n}\n\nexport type ImpactFileListItem = HealthRemedies;\n\nexport type ImpactFileList = ImpactFileListItem[];\n\n/**\n * Contains the outline information of an article\n */\nexport interface ParsedArticleHead {\n  id: string;\n  title: string;\n  xmlFullTextDownloadLink: string;\n  impacted: string;\n  recommendation: string;\n  impactedSynonyms: string[];\n  recommendationSynonyms: string[];\n}\n\nexport interface ParsedArticle {\n  head: ParsedArticleHead;\n  paragraphs: ParsedArticleParagraph[];\n}\n\nexport interface ParsedArticleParagraph {\n  body: string;\n  correlationScore: number;\n}\n\nexport interface ParsedArticleParagraphStandalone\n  extends ParsedArticleParagraph {\n  head: ParsedArticleHead;\n  backsUpClaim: ArticleParagraphBacksUpClaim;\n}\n\nexport interface Parser<IRet> {\n  parserF: (inputSource: string, opts?: any) => Promise<IRet[] | IRet>;\n}\n\nexport interface ScholarsParserOpts extends UrlWithTag {\n  tag: {\n    recommendation: string;\n    impacted: string;\n    impactedSynonyms: string[];\n  };\n}\n\nexport interface UrlWithTag {\n  url: string;\n  tag?: any;\n}\n","export * from './scraper/scholars-scraper';\n","import {\n  ParsedArticleHead,\n  ScholarsParserOpts,\n  UrlWithTag,\n} from '@foodmedicine/interfaces';\n// eslint-disable-next-line @nrwl/nx/enforce-module-boundaries\nimport { Scraper } from '@foodmedicine/scraper';\nimport * as parsers from '../parsers';\nimport { getSynonyms } from '@foodmedicine/word-explorer';\n\n/**\n * Construct the google scholars url which will be scraped\n * @param pageSize - the number of articles to get\n */\nfunction createScholarsUrl(\n  impacted: string,\n  solution: string,\n  pageSize: number,\n  synonym = true\n): string {\n  return encodeURI(\n    `https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=${solution} ${impacted}&synonym=${synonym}&pageSize=${pageSize}`\n  );\n}\n\n/**\n * Find all the PDF urls which could have related articles to the remedy\n * @param remedy - one particular impacted and a set of recommendations\n * @returns an array of PDF urls\n */\nexport async function runScholarsScraper(\n  impacted: string,\n  recommendation: string,\n  pageSize = 25\n): Promise<ParsedArticleHead[]> {\n  const queryUrl = createScholarsUrl(impacted, recommendation, pageSize);\n  const impactedSynonyms = await getSynonyms(impacted);\n  const remedyScraper = new Scraper<ParsedArticleHead>(parsers.ScholarsParser, {\n    url: queryUrl,\n    tag: {\n      recommendation: recommendation,\n      impacted: impacted,\n      impactedSynonyms,\n    },\n  } as UrlWithTag);\n\n  const articleHeads = await remedyScraper.run();\n  return articleHeads;\n}\n","import { Parser, UrlWithTag } from '@foodmedicine/interfaces';\nimport fetch from 'node-fetch';\nimport { parse } from 'querystring';\n\n/**\n * A generalized scraper abstraction class\n * This class can scrape different sites of pdfs\n * @param IRet - is the return interface for a scraped site or article\n */\nexport class Scraper<IRet> {\n  private urlsWithTags: UrlWithTag[];\n  private parser: Parser<IRet>;\n  constructor(parser: Parser<IRet>, ...urlsWithTags: UrlWithTag[]) {\n    this.parser = parser;\n    this.urlsWithTags = urlsWithTags;\n  }\n\n  /**\n   * Retrieves the source code of a url\n   */\n  async getSiteSource(url: string): Promise<string> {\n    const ret = await fetch(url);\n    return await ret.text();\n  }\n\n  async scrapeSiteSinglePage(url: string, opts: any): Promise<IRet[]> {\n    console.info(\"Scraping for\", url)\n    const source = await this.getSiteSource(url);\n    return await this.parser.parserF(source, opts) as IRet[];\n  }\n\n  /**\n   * Run the scraper for the inputed websites\n   */\n  public async run(): Promise<IRet[]> {\n    // create an array of promises to concurrently perform web scraping\n    const pageScrapingProms = this.urlsWithTags.map(async (urlWithTag) =>\n      await this.scrapeSiteSinglePage(urlWithTag.url, {\n        tag: urlWithTag.tag,\n      })\n    );\n    const scrapedRes = await Promise.all(pageScrapingProms);\n\n    // Because each individual page returns an array of results,\n    // results will be an array of arrays which should be flattened\n    return scrapedRes.flat();\n  }\n}\n","import {\n  Parser,\n  ParsedArticleHead,\n  ScholarsParserOpts,\n} from '@foodmedicine/interfaces';\nimport * as xmlJs from 'xml2js';\nimport * as wordExplorer from '@foodmedicine/word-explorer'\n\n/**\n * A parser for https://www.ebi.ac.uk/europepmc/webservices/rest/\n */\nexport const ScholarsParser: Parser<ParsedArticleHead> = {\n  parserF: async (xml, opts?: ScholarsParserOpts) => {\n    if (!opts) {\n      throw 'Options must be passed into this scraper';\n    }\n    const parser = new xmlJs.Parser();\n    const jsonRes = await parser.parseStringPromise(xml);\n    const allResults = jsonRes.responseWrapper.resultList[0].result;\n    const recommendationSynonyms = await wordExplorer.getSynonyms(opts.tag.recommendation);\n    const parsedHeads: ParsedArticleHead[] = allResults.map((res) => {\n      return {\n        id: res.id[0],\n        title: res.title[0],\n        xmlFullTextDownloadLink: `https://www.ebi.ac.uk/europepmc/webservices/rest/${res.id[0]}/fullTextXML`,\n        recommendation: opts.tag.recommendation,\n        impacted: opts.tag.impacted,\n        impactedSynonyms: opts.tag.impactedSynonyms,\n        recommendationSynonyms: recommendationSynonyms,\n      };\n    });\n    return parsedHeads;\n  },\n};\n","import * as util from 'util';\nimport * as wordnet from 'wordnet';\nimport * as natural from 'natural';\n\nconst wordnetLookup = util.promisify(wordnet.lookup);\n\nexport async function getSynonyms(word: string): Promise<string[]> {\n  // n is for the nouns\n  const synonymWordsArrProms: Promise<string[][]>[] = word.split(' ').map(\n    async (individualWord): Promise<string[][]> => {\n      try {\n        return (\n          await wordnetLookup(natural.PorterStemmer.stem(individualWord))\n        ).map((def) => def.meta.words.map((item) => item.word));\n      } catch (e) {\n        console.error(\n          'Error finding synonyms for %s. Error %s',\n          individualWord,\n          e\n        );\n        return [[]];\n      }\n    }\n  );\n  const synonymWordsArr: string[][][] = await Promise.all(synonymWordsArrProms);\n  // make sure the items in the array are all truthy\n  const synonymWords = synonymWordsArr\n    .flat(Infinity)\n    .filter((synonym) => synonym && !word.includes(synonym));\n  if (!synonymWords) {\n    return [];\n  }\n  console.info('Found synonym words for %s:', word, synonymWords);\n  return synonymWords;\n}\n\n// TODO add glossary def to word meaning\n","export * from './parser';\nexport * from './correlation-score/correlation-score';\n","export * from './ebi-parser';\n","import {\n  ParsedArticle,\n  Parser,\n  ParsedArticleParagraph,\n  EbiParserOptions,\n} from '@foodmedicine/interfaces';\nimport * as cheerio from 'cheerio';\n\n/**\n * A parser for https://www.ebi.ac.uk/europepmc/webservices/rest/\n */\nexport const EbiParser: Parser<ParsedArticle> = {\n  parserF: async (xml: string, opts?: EbiParserOptions) => {\n    if (!opts?.parsedArticleHead) {\n      throw 'Please add in the parsed head';\n    }\n    const $ = cheerio.load(xml);\n    const paragraphTexts: string[] = $('p')\n      .map((i, el) => $(el).text())\n      .get();\n    const paragraphs: ParsedArticleParagraph[] = paragraphTexts.map(\n      (paragraphText) =>\n        opts.getCorrelationScore(\n          paragraphText,\n          opts.parsedArticleHead.impacted,\n          opts.parsedArticleHead.recommendation,\n          opts.parsedArticleHead.impactedSynonyms,\n          opts.parsedArticleHead.recommendationSynonyms\n        )\n    );\n    const article: ParsedArticle = {\n      head: opts.parsedArticleHead,\n      paragraphs,\n    };\n    return article;\n  },\n};\n","import {\n  ParsedArticleHead,\n  Parser,\n  ParsedArticle,\n  ParsedArticleParagraph,\n  EbiParserOptions,\n} from '@foodmedicine/interfaces';\nimport * as fetch from 'node-fetch';\nimport { correlationWeights, cutOffs } from './correlation-constants';\nimport * as natural from 'natural';\n\nconst tokenizer = new natural.WordTokenizer();\n\nasync function downloadArticle(url: string): Promise<string> {\n  const ret = await fetch(url);\n  return await ret.text();\n}\n\n/**\n * Find word frequencies through fuzzy search\n */\nfunction findWordFreqFuzzy(word: string, paragraph: string): number {\n  const tokenizedParagraph = tokenizer.tokenize(paragraph);\n  const overallFreqScore = tokenizedParagraph.reduce(\n    (freq: number, paragraphWord) => {\n      // distance ranges from 0 to 1. 1 being a perfect match\n      const distance = natural.JaroWinklerDistance(word, paragraphWord);\n      return freq + (distance > cutOffs.minimumWordDistance ? distance : 0);\n    },\n    0\n  );\n  return overallFreqScore;\n}\n\nfunction findWordsFreqFuzzy(words: string[], paragraph: string): number {\n  return words\n    .map((word) => findWordFreqFuzzy(word, paragraph))\n    .reduce((total, score) => total + score, 0);\n}\n\n/**\n * Compute the correlation score based off of the inputs\n * Current features include impact frequencies, recommendation frequencies, impact x recommendation\n * Paragraph length\n */\nfunction computeScore(\n  impactFreq: number,\n  recommendationFreq: number,\n  impactSynonymFreq: number,\n  recommendationSynonymFreq: number,\n  paragraphWordCount: number\n): number {\n  const impactScore = impactFreq * correlationWeights.impactWordFreq;\n  const recommendationScore =\n    recommendationFreq * correlationWeights.recommendationWordFreq;\n  const impactSynonymScore =\n    impactSynonymFreq * correlationWeights.impactSynonymWordFreq;\n  const recommendationSynonymScore =\n    recommendationSynonymFreq *\n    correlationWeights.recommendationSynonymWordFreq;\n  const crossScore =\n    impactFreq *\n    recommendationFreq *\n    correlationWeights.impactCrossRecommendation;\n  // ensures that both impact and recommendation are seen in the same paragraph\n  return (\n    impactScore +\n    recommendationScore +\n    crossScore +\n    impactSynonymScore +\n    recommendationSynonymScore\n  );\n}\n\nfunction stemString(input: string) {\n  return natural.PorterStemmer.tokenizeAndStem(input).join(' ');\n}\n\nfunction getWholeParagraphCorrelationScore(\n  paragraph: string,\n  impacted: string,\n  recommendation: string,\n  impactedSynonyms: string[],\n  recommendationSynonyms: string[]\n): ParsedArticleParagraph {\n  const impactedStem = stemString(impacted);\n  const paragraphStemmed = stemString(paragraph);\n  const recommendationStem = stemString(recommendation);\n  const impactSynonymFreq = findWordsFreqFuzzy(\n    impactedSynonyms,\n    paragraphStemmed\n  );\n  const recommendationSynonymFreq = findWordsFreqFuzzy(\n    recommendationSynonyms,\n    paragraphStemmed\n  );\n\n  const correlationScore = computeScore(\n    findWordFreqFuzzy(impactedStem, paragraphStemmed),\n    findWordFreqFuzzy(recommendationStem, paragraphStemmed),\n    impactSynonymFreq,\n    recommendationSynonymFreq,\n    paragraph.split(' ').length\n  );\n  return {\n    body: paragraph,\n    correlationScore,\n  };\n}\n\n/**\n * Get the correlation score for the segment of a paragraph with the most matches\n * Will shorten the paragraph as much as possible while trying to mantain the same correlation score\n * + or - {@code maintainWithinPercent}\n */\nfunction getShortestParagraphCorrelationScore(\n  paragraph: string,\n  impacted: string,\n  recommendation: string,\n  impactedSynonyms: string[],\n  recommendationSynonyms: string[],\n  maintainWithinPercent = cutOffs.maintainScoreWithinPercent\n): ParsedArticleParagraph {\n  function calculatePercentageDifference(x: number, y: number): number {\n    return Math.abs((x - y) / x) * 100;\n  }\n  const sentences = paragraph.split('.');\n  // remove the last element if it is empty\n  if (!sentences[sentences.length - 1]) {\n    sentences.pop();\n  }\n  const initScore = getWholeParagraphCorrelationScore(\n    paragraph,\n    impacted,\n    recommendation,\n    impactedSynonyms,\n    recommendationSynonyms\n  ).correlationScore;\n  let currentScore = initScore;\n  let leftInd = 0;\n  let rightIndNonInclusive = sentences.length;\n  // Attempts to remove sentences from the beginning of the paragraph\n  // while having the correlation score stay within half of the {@code maintainWithinPercent}\n  while (\n    calculatePercentageDifference(initScore, currentScore) <=\n      maintainWithinPercent / 2 &&\n    leftInd != rightIndNonInclusive\n  ) {\n    currentScore = getWholeParagraphCorrelationScore(\n      sentences.slice(leftInd, rightIndNonInclusive).join('.'),\n      impacted,\n      recommendation,\n      impactedSynonyms,\n      recommendationSynonyms\n    ).correlationScore;\n    leftInd++;\n  }\n  // Attempts to remove sentences from the end of the paragraph\n  // while having the correlation score stay within {@code maintainWithinPercent}\n  while (\n    calculatePercentageDifference(initScore, currentScore) <=\n      maintainWithinPercent &&\n    leftInd != rightIndNonInclusive\n  ) {\n    currentScore = getWholeParagraphCorrelationScore(\n      sentences.slice(leftInd, rightIndNonInclusive).join('.'),\n      impacted,\n      recommendation,\n      impactedSynonyms,\n      recommendationSynonyms\n    ).correlationScore;\n    rightIndNonInclusive--;\n  }\n  // Increment {@code rightIndNonInclusive} because the new correlation score may be\n  // over the alloted percentage range after the prior loop. Thus, the last sentence removed\n  // is added back\n  rightIndNonInclusive =\n    rightIndNonInclusive < sentences.length\n      ? rightIndNonInclusive + 1\n      : rightIndNonInclusive;\n  return {\n    correlationScore: currentScore,\n    body: sentences.slice(leftInd, rightIndNonInclusive).join('.'),\n  };\n}\n\nexport async function evaluateArticle(\n  articleHead: ParsedArticleHead,\n  parser: Parser<ParsedArticle>\n): Promise<ParsedArticle> {\n  const inputXML = await downloadArticle(articleHead.xmlFullTextDownloadLink);\n  console.info(\n    `Downloaded XML for ${articleHead.impacted} for ${articleHead.recommendation} with url ${articleHead.xmlFullTextDownloadLink}`\n  );\n  // Parser functions return an array, but in this case, only the first result is relevant\n  return (await parser.parserF(inputXML, {\n    parsedArticleHead: articleHead,\n    impacted: articleHead.impacted,\n    recommendation: articleHead.recommendation,\n    getCorrelationScore: getShortestParagraphCorrelationScore,\n  } as EbiParserOptions)) as ParsedArticle;\n}\n","import * as express from 'express';\nimport * as bodyParser from 'body-parser';\nimport router from './controllers';\n\nconst app = express();\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: true }));\n\napp.use('/api', router);\n\nexport default app;\n","import * as express from 'express';\nimport searchRouter from './search';\n\nconst router = express.Router();\n\nrouter.use('/search', searchRouter);\n\nexport default router;\n","import * as express from 'express';\nimport { findQueryResults } from '../daos';\n\nconst router = express.Router();\n\n/**\n * Search the database for correlated paragraphs\n * @query q - query string\n * @query maxNumberOfParagraphs - optional max number of paragraphs\n * @query numberOfArticles - optional number of articles to search\n */\nrouter.get(\n  '/',\n  async (\n    req: express.Request,\n    res: express.Response,\n    next: express.NextFunction\n  ) => {\n    const query = req.query.q as string;\n    const results = await findQueryResults(query, {\n      numberOfArticles: parseInt(req.query.numberOfArticles as string),\n      maxNumberOfParagraphs: parseInt(\n        req.query.maxNumberOfParagraphs as string\n      ),\n    });\n    res.status(200).json(results);\n  }\n);\n\nexport default router;\n","export * from './search'","export * from './lib/interfaces';\n","export * from './lib';\n","export * from './lib/scraper';\n","export * from './scholars-parser';\n","module.exports = require(\"xml2js\");","module.exports = require(\"util\");","module.exports = require(\"wordnet\");","module.exports = require(\"cheerio\");","import app from './app/app'\n\nconst port = process.env.port || 3333;\nconst server = app.listen(port, () => {\n  console.info(`Listening at http://localhost:${port}/api`);\n});\nserver.on('error', console.error);\n"],"sourceRoot":""}