{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///external \"tslib\"","webpack:///./libs/interfaces/src/index.ts","webpack:///external \"express\"","webpack:///external \"node-fetch\"","webpack:///./libs/article-parser/src/lib/parser/index.ts","webpack:///external \"natural\"","webpack:///./libs/article-parser/src/lib/correlation-score/correlation-constants.ts","webpack:///./libs/scraper/src/index.ts","webpack:///./libs/scholars-scraper/src/lib/parsers/index.ts","webpack:///external \"xml2js\"","webpack:///./libs/scholars-scraper/src/lib/scraper/europepmc-scraper.ts","webpack:///./libs/pdf-explorer/src/lib/pdf-explorer-constants.ts","webpack:///external \"body-parser\"","webpack:///./libs/scholars-scraper/src/lib/scraper/arxiv-scraper.ts","webpack:///./apps/api-express/src/app/daos/search.ts","webpack:///./libs/interfaces/src/lib/interfaces.ts","webpack:///./libs/scholars-scraper/src/lib/index.ts","webpack:///./libs/scholars-scraper/src/lib/scraper/scholars-scraper.ts","webpack:///./libs/scraper/src/lib/scraper.ts","webpack:///./libs/scholars-scraper/src/lib/parsers/europepmc-parser.ts","webpack:///./libs/scholars-scraper/src/lib/parsers/arxiv-parser.ts","webpack:///./libs/word-explorer/src/lib/word-explorer.ts","webpack:///./libs/article-parser/src/lib/index.ts","webpack:///./libs/article-parser/src/lib/parser/europepmc-parser.ts","webpack:///./libs/article-parser/src/lib/parser/arxiv-parser.ts","webpack:///./libs/pdf-explorer/src/lib/pdf-explorer.ts","webpack:///./libs/article-parser/src/lib/correlation-score/correlation-score.ts","webpack:///./apps/api-express/src/app/app.ts","webpack:///external \"cors\"","webpack:///./apps/api-express/src/app/controllers/index.ts","webpack:///./apps/api-express/src/app/controllers/search.ts","webpack:///./apps/api-express/src/app/daos/index.ts","webpack:///./libs/scholars-scraper/src/index.ts","webpack:///./libs/word-explorer/src/index.ts","webpack:///external \"util\"","webpack:///external \"wordnet\"","webpack:///./libs/article-parser/src/index.ts","webpack:///external \"cheerio\"","webpack:///./libs/pdf-explorer/src/index.ts","webpack:///external \"pdf-parse\"","webpack:///./apps/api-express/src/main.ts"],"names":[],"mappings":";QAAA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;;QAEA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;;;QAGA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;QACA,0CAA0C,gCAAgC;QAC1E;QACA;;QAEA;QACA;QACA;QACA,wDAAwD,kBAAkB;QAC1E;QACA,iDAAiD,cAAc;QAC/D;;QAEA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA,yCAAyC,iCAAiC;QAC1E,gHAAgH,mBAAmB,EAAE;QACrI;QACA;;QAEA;QACA;QACA;QACA,2BAA2B,0BAA0B,EAAE;QACvD,iCAAiC,eAAe;QAChD;QACA;QACA;;QAEA;QACA,sDAAsD,+DAA+D;;QAErH;QACA;;;QAGA;QACA;;;;;;;AClFA,kC;;;;;;;ACAA;AAAA;AAAA;AAAiC;;;;;;;ACAjC,oC;;;;;;ACAA,uC;;;;;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAmC;AACJ;;;;;;;ACD/B,oC;;;;;;;ACAA;AAAA;AAAO,MAAM,kBAAkB,GAAG;IAChC,oBAAoB,EAAE,GAAG;IACzB,aAAa,EAAE,CAAC;CACjB,CAAC;AAEK,MAAM,OAAO,GAAG;IACrB,mBAAmB,EAAE,IAAI;IACzB,0BAA0B,EAAE,EAAE;CAC/B,CAAC;;;;;;;;ACRF;AAAA;AAAA;AAA8B;;;;;;;;ACA9B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAmC;AACJ;;;;;;;ACD/B,mC;;;;;;;;;;;;;ACKA,8DAA8D;AACd;AACH;AAE7C;;;GAGG;AACH,SAAS,kBAAkB,CACzB,KAAa,EACb,QAAgB,EAChB,OAAO,GAAG,IAAI;IAEd,OAAO,SAAS,CACd,iEAAiE,KAAK,YAAY,OAAO,aAAa,QAAQ,EAAE,CACjH,CAAC;AACJ,CAAC;AAEM,SAAe,oBAAoB,CACxC,KAAa,EACb,aAAuB,EACvB,QAAgB;;QAEhB,MAAM,QAAQ,GAAG,kBAAkB,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;QACrD,MAAM,aAAa,GAAG,IAAI,qEAAO,CAAoB,gEAAe,EAAE;YACpE,GAAG,EAAE,QAAQ;YACb,GAAG,EAAE;gBACH,KAAK;gBACL,aAAa;aACd;SACY,CAAC,CAAC;QAEjB,MAAM,YAAY,GAAG,MAAM,aAAa,CAAC,GAAG,EAAE,CAAC;QAC/C,OAAO,YAAY,CAAC;IACtB,CAAC;CAAA;;;;;;;;ACvCD;AAAO,MAAM,SAAS,GAAG;IACvB,aAAa,EAAE,CAAC;IAChB,uBAAuB,EAAE,CAAC;IAC1B,4BAA4B,EAAE,EAAE;CACjC,CAAC;;;;;;;ACJF,wC;;;;;;;;;;;;;ACKA,8DAA8D;AACd;AACP;AAEzC;;;GAGG;AACH,SAAS,cAAc,CACrB,KAAa,EACb,QAAgB;IAEhB,OAAO,SAAS,CACd,sDAAsD,KAAK,wBAAwB,QAAQ,EAAE,CAC9F,CAAC;AACJ,CAAC;AAEM,SAAe,gBAAgB,CACpC,KAAa,EACb,aAAuB,EACvB,QAAgB;;QAEhB,MAAM,QAAQ,GAAG,cAAc,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;QACjD,MAAM,aAAa,GAAG,IAAI,qEAAO,CAAoB,4DAAW,EAAE;YAChE,GAAG,EAAE,QAAQ;YACb,GAAG,EAAE;gBACH,KAAK;gBACL,aAAa;aACd;SACY,CAAC,CAAC;QAEjB,MAAM,YAAY,GAAG,MAAM,aAAa,CAAC,GAAG,EAAE,CAAC;QAC/C,OAAO,YAAY,CAAC;IACtB,CAAC;CAAA;;;;;;;;;;;;;;;ACjCiC;AACkC;AACN;AAEvD,SAAe,gBAAgB,CACpC,KAAa,EACb,IAGC;;QAED,MAAM,YAAY,GAAG,MAAM,iGAAkB,CAC3C,KAAK,EACL,2EAAU,CAAC,OAAO,EAClB,KAAI,aAAJ,IAAI,uBAAJ,IAAI,CAAE,gBAAgB,KAAI,EAAE,CAC7B,CAAC;QACF,MAAM,aAAa,GAA6B,YAAY,CAAC,GAAG,CAC9D,CAAO,WAAW,EAAE,EAAE,CAAC;YACrB,MAAM,gBAAgB,GAAkB,MAAM,oFAA6B,CACzE,WAAW,CACZ,CAAC;YACF,OAAO,gBAAgB,CAAC;QAC1B,CAAC,EACF,CAAC;QACF,MAAM,oBAAoB,GAAoB,MAAM,OAAO,CAAC,GAAG,CAC7D,aAAa,CACd,CAAC;QACF,MAAM,uBAAuB,GAAuC,EAAE,CAAC;QACvE,2FAA2F;QAC3F,mDAAmD;QACnD,oBAAoB,CAAC,OAAO,CAAC,CAAC,OAAO,EAAE,EAAE;YACvC,MAAM,oBAAoB,GAAuC,OAAO,CAAC,UAAU,CAAC,GAAG,CACrF,CAAC,SAAiC,EAAE,EAAE;gBACpC,uBACE,IAAI,EAAE,OAAO,CAAC,IAAI,IACf,SAAS,EACZ;YACJ,CAAC,CACF,CAAC;YACF,uBAAuB,CAAC,IAAI,CAAC,GAAG,oBAAoB,CAAC,CAAC;QACxD,CAAC,CAAC,CAAC;QACH,kDAAkD;QAClD,uBAAuB,CAAC,IAAI,CAC1B,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,gBAAgB,GAAG,CAAC,CAAC,gBAAgB,CAClD,CAAC;QACF,MAAM,+BAA+B,GAAG,uBAAuB,CAAC,MAAM,CACpE,CAAC,SAAS,EAAE,EAAE,WAAC,uBAAS,CAAC,IAAI,0CAAE,IAAI,GAAG,MAAM,IAAG,CAAC,IACjD,CAAC;QACF,OAAO,+BAA+B,CAAC,KAAK,CAC1C,CAAC,EACD,KAAI,aAAJ,IAAI,uBAAJ,IAAI,CAAE,qBAAqB,KAAI,uBAAuB,CAAC,MAAM,CAC9D,CAAC;IACJ,CAAC;CAAA;;;;;;;;ACPD;AAAA,IAAY,UAIX;AAJD,WAAY,UAAU;IACpB,iDAAW;IACX,6CAAK;IACL,uDAAU;AACZ,CAAC,EAJW,UAAU,KAAV,UAAU,QAIrB;;;;;;;;ACtDD;AAAA;AAAA;AAA2C;;;;;;;;;;;;;;;;ACA8B;AACd;AACR;AAEO;AAC1D;;;GAGG;AACI,SAAe,kBAAkB,CACtC,KAAa,EACb,EAAc,EACd,QAAgB;;QAEhB,MAAM,aAAa,GAAG,MAAM,uFAAW,CAAC,KAAK,CAAC,CAAC;QAC/C,IAAI,EAAE,KAAK,2EAAU,CAAC,OAAO,EAAE;YAC7B,kHAAkH;YAClH,6DAA6D;YAC7D,MAAM,aAAa,GAAG,uFAAoB,CAAC,KAAK,EAAE,aAAa,EAAE,IAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,CAAC,CAAC,CAAC,CAAC;YAC1F,MAAM,SAAS,GAAG,+EAAgB,CAAC,KAAK,EAAE,aAAa,EAAE,IAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,CAAC,CAAC,CAAC,CAAC;YAClF,MAAM,cAAc,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC,aAAa,EAAE,SAAS,CAAC,CAAC,CAAC;YAC/D,OAAO,CAAC,MAAM,cAAc,CAAC,CAAC,IAAI,EAAE,CAAC;SACtC;aAAM,IAAI,EAAE,KAAK,2EAAU,CAAC,UAAU,EAAE;YACvC,OAAO,uFAAoB,CAAC,KAAK,EAAE,aAAa,EAAE,QAAQ,CAAC,CAAC;SAC7D;aAAM,IAAI,EAAE,KAAK,2EAAU,CAAC,KAAK,EAAE;YAClC,OAAO,+EAAgB,CAAC,KAAK,EAAE,aAAa,EAAE,QAAQ,CAAC,CAAC;SACzD;QACD,OAAO,uFAAoB,CAAC,KAAK,EAAE,aAAa,EAAE,QAAQ,CAAC,CAAC;IAC9D,CAAC;CAAA;;;;;;;;;;;;;;AC3B8B;AAG/B;;;;GAIG;AACI,MAAM,OAAO;IAGlB,YAAY,MAAoB,EAAE,GAAG,YAA0B;QAC7D,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;QACrB,IAAI,CAAC,YAAY,GAAG,YAAY,CAAC;IACnC,CAAC;IAED;;OAEG;IACG,aAAa,CAAC,GAAW;;YAC7B,MAAM,GAAG,GAAG,MAAM,iDAAK,CAAC,GAAG,CAAC,CAAC;YAC7B,OAAO,MAAM,GAAG,CAAC,IAAI,EAAE,CAAC;QAC1B,CAAC;KAAA;IAEK,oBAAoB,CAAC,GAAW,EAAE,IAAS;;YAC/C,OAAO,CAAC,IAAI,CAAC,cAAc,EAAE,GAAG,CAAC;YACjC,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC;YAC7C,OAAO,MAAM,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,EAAE,IAAI,CAAW,CAAC;QAC3D,CAAC;KAAA;IAED;;OAEG;IACU,GAAG;;YACd,mEAAmE;YACnE,MAAM,iBAAiB,GAAG,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAO,UAAU,EAAE,EAAE;gBACnE,aAAM,IAAI,CAAC,oBAAoB,CAAC,UAAU,CAAC,GAAG,EAAE;oBAC9C,GAAG,EAAE,UAAU,CAAC,GAAG;iBACpB,CAAC;cAAA,CACH,CAAC;YACF,MAAM,UAAU,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;YAExD,4DAA4D;YAC5D,+DAA+D;YAC/D,OAAO,UAAU,CAAC,IAAI,EAAE,CAAC;QAC3B,CAAC;KAAA;CACF;;;;;;;;;;;;;;;AC1CiC;AACF;AAEhC;;GAEG;AACI,MAAM,eAAe,GAA8B;IACxD,OAAO,EAAE,CAAO,GAAG,EAAE,IAAyB,EAAE,EAAE,CAAC;QACjD,IAAI,CAAC,IAAI,EAAE;YACT,MAAM,0CAA0C,CAAC;SAClD;QACD,MAAM,MAAM,GAAG,IAAI,6CAAY,EAAE,CAAC;QAClC,MAAM,OAAO,GAAG,MAAM,MAAM,CAAC,kBAAkB,CAAC,GAAG,CAAC,CAAC;QACrD,MAAM,UAAU,GAAG,OAAO,CAAC,eAAe,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC;QAChE,MAAM,WAAW,GAAwB,UAAU,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,EAAE;YAC9D,OAAO;gBACL,EAAE,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC;gBACb,KAAK,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC;gBACnB,oBAAoB,EAAE,oDAAoD,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,cAAc;gBACjG,KAAK,EAAE,IAAI,CAAC,GAAG,CAAC,KAAK;gBACrB,aAAa,EAAE,IAAI,CAAC,GAAG,CAAC,aAAa;gBACrC,MAAM,EAAE,2EAAU,CAAC,UAAU;aAC9B,CAAC;QACJ,CAAC,CAAC,CAAC;QACH,OAAO,WAAW,CAAC;IACrB,CAAC;CACF,CAAC;;;;;;;;;;;;;;;AC1BgC;AACF;AAEhC;;GAEG;AACI,MAAM,WAAW,GAA8B;IACpD,OAAO,EAAE,CAAO,GAAG,EAAE,IAAyB,EAAE,EAAE,CAAC;QACjD,IAAI,CAAC,IAAI,EAAE;YACT,MAAM,0CAA0C,CAAC;SAClD;QACD,MAAM,MAAM,GAAG,IAAI,6CAAY,EAAE,CAAC;QAClC,MAAM,OAAO,GAAG,MAAM,MAAM,CAAC,kBAAkB,CAAC,GAAG,CAAC,CAAC;QACrD,MAAM,UAAU,GAAG,OAAO,CAAC,IAAI,CAAC,KAAK,IAAI,EAAE,CAAC;QAC5C,MAAM,WAAW,GAAwB,UAAU;aAChD,GAAG,CAAC,CAAC,GAAG,EAAE,EAAE;YACX,MAAM,gBAAgB,GAAG,GAAG,CAAC,IAAI;iBAC9B,MAAM,CAAC,CAAC,QAAQ,EAAE,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,KAAK,KAAK,KAAK,CAAC;iBAChD,GAAG,CAAC,CAAC,QAAQ,EAAE,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;YACtC,MAAM,oBAAoB,GAAG,gBAAgB,CAAC,CAAC,CAAC,IAAI,IAAI,CAAC;YACzD,OAAO;gBACL,EAAE,EAAE,GAAG,CAAC,EAAE;gBACV,KAAK,EAAE,GAAG,CAAC,KAAK;gBAChB,oBAAoB;gBACpB,KAAK,EAAE,IAAI,CAAC,GAAG,CAAC,KAAK;gBACrB,aAAa,EAAE,IAAI,CAAC,GAAG,CAAC,aAAa;gBACrC,MAAM,EAAE,2EAAU,CAAC,KAAK;aACzB,CAAC;QACJ,CAAC,CAAC;aACD,MAAM,CAAC,CAAC,UAAU,EAAE,EAAE,CAAC,UAAU,CAAC,oBAAoB,KAAK,IAAI,CAAC,CAAC;QACpE,OAAO,WAAW,CAAC;IACrB,CAAC;CACF,CAAC;;;;;;;;;;;;;;;;;;ACrC2B;AACM;AACA;AAEnC,MAAM,aAAa,GAAG,8CAAc,CAAC,8CAAc,CAAC,CAAC;AAE9C,SAAe,WAAW,CAAC,IAAY;;QAC5C,qBAAqB;QACrB,MAAM,oBAAoB,GAA0B,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,GAAG,CACrE,CAAO,cAAc,EAAuB,EAAE,CAAC;YAC7C,IAAI;gBACF,OAAO,CACL,MAAM,aAAa,CAAC,qDAAqB,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC,CAChE,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;aACzD;YAAC,OAAO,CAAC,EAAE;gBACV,OAAO,CAAC,KAAK,CACX,yCAAyC,EACzC,cAAc,EACd,CAAC,CACF,CAAC;gBACF,OAAO,CAAC,EAAE,CAAC,CAAC;aACb;QACH,CAAC,EACF,CAAC;QACF,MAAM,eAAe,GAAiB,MAAM,OAAO,CAAC,GAAG,CAAC,oBAAoB,CAAC,CAAC;QAC9E,kDAAkD;QAClD,MAAM,YAAY,GAAG,eAAe;aACjC,IAAI,CAAC,QAAQ,CAAC;aACd,MAAM,CAAC,CAAC,OAAO,EAAE,EAAE,CAAC,OAAO,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,CAAC;QAC3D,IAAI,CAAC,YAAY,EAAE;YACjB,OAAO,EAAE,CAAC;SACX;QACD,OAAO,CAAC,IAAI,CAAC,6BAA6B,EAAE,IAAI,EAAE,YAAY,CAAC,CAAC;QAChE,OAAO,YAAY,CAAC;IACtB,CAAC;CAAA;AAED,wCAAwC;;;;;;;;ACpCxC;AAAA;AAAA;AAAA;AAAyB;AAC6B;;;;;;;;;;;;;;;;ACKxB;AACK;AAEnC,SAAe,eAAe,CAAC,GAAW;;QACxC,MAAM,GAAG,GAAG,MAAM,iDAAK,CAAC,GAAG,CAAC,CAAC;QAC7B,OAAO,MAAM,GAAG,CAAC,IAAI,EAAE,CAAC;IAC1B,CAAC;CAAA;AAED;;GAEG;AACI,MAAM,eAAe,GAA0B;IACpD,OAAO,EAAE,CAAO,eAAuB,EAAE,IAAuB,EAAE,EAAE,CAAC;QACnE,MAAM,GAAG,GAAG,MAAM,eAAe,CAAC,eAAe,CAAC,CAAC;QACnD,IAAI,EAAC,IAAI,aAAJ,IAAI,uBAAJ,IAAI,CAAE,iBAAiB,GAAE;YAC5B,MAAM,+BAA+B,CAAC;SACvC;QACD,MAAM,CAAC,GAAG,4CAAY,CAAC,GAAG,CAAC,CAAC;QAC5B,MAAM,cAAc,GAAa,CAAC,CAAC,GAAG,CAAC;aACpC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC;aAC5B,GAAG,EAAE,CAAC;QACT,MAAM,UAAU,GAA6B,cAAc,CAAC,GAAG,CAC7D,CAAC,aAAa,EAAE,EAAE,CAChB,IAAI,CAAC,mBAAmB,CACtB,aAAa,EACb,IAAI,CAAC,iBAAiB,CAAC,KAAK,EAC5B,IAAI,CAAC,iBAAiB,CAAC,aAAa,CACrC,CACJ,CAAC;QACF,MAAM,OAAO,GAAkB;YAC7B,IAAI,EAAE,IAAI,CAAC,iBAAiB;YAC5B,UAAU;SACX,CAAC;QACF,OAAO,OAAO,CAAC;IACjB,CAAC;CACF,CAAC;;;;;;;;;;;;;ACnCmE;AAErE;;GAEG;AACI,MAAM,WAAW,GAA0B;IAChD,OAAO,EAAE,CAAO,OAAe,EAAE,IAAmB,EAAE,EAAE,CAAC;QACvD,IAAI,EAAC,IAAI,aAAJ,IAAI,uBAAJ,IAAI,CAAE,iBAAiB,GAAE;YAC5B,MAAM,IAAI,KAAK,CAAC,+BAA+B,CAAC,CAAC;SAClD;QACD,MAAM,cAAc,GAAG,MAAM,kGAAuB,CAAC,OAAO,CAAC,CAAC;QAC9D,IAAI;YACF,MAAM,UAAU,GAA6B,cAAc,CAAC,GAAG,CAC7D,CAAC,aAAa,EAAE,EAAE,CAChB,IAAI,CAAC,mBAAmB,CACtB,aAAa,EACb,IAAI,CAAC,iBAAiB,CAAC,KAAK,EAC5B,IAAI,CAAC,iBAAiB,CAAC,aAAa,CACrC,CACJ,CAAC;YACF,MAAM,OAAO,GAAkB;gBAC7B,IAAI,EAAE,IAAI,CAAC,iBAAiB;gBAC5B,UAAU;aACX,CAAC;YACF,OAAO,OAAO,CAAC;SAChB;QAAC,OAAO,CAAC,EAAE;YACV,OAAO,CAAC,KAAK,CACX,yDAAyD,EACzD,CAAC,CACF,CAAC;YACF,OAAO;gBACL,IAAI,EAAE,IAAI,CAAC,iBAAiB;gBAC5B,UAAU,EAAE,EAAE;aACf,CAAC;SACH;IACH,CAAC;CACF,CAAC;;;;;;;;;;;;;;;;;;AC1C6B;AACH;AACyB;AAErD;;GAEG;AACH,SAAS,4BAA4B,CAAC,IAAY;IAChD,OAAO,IAAI,CAAC,MAAM,GAAG,yEAAS,CAAC,4BAA4B,IAAI,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC;AACpF,CAAC;AAED,SAAS,YAAY,CAAC,IAAY,EAAE,OAAe;IACjD,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,MAAM,CAAC;AAC5C,CAAC;AAED,SAAS,4BAA4B,CAAC,SAAmB;IACvD,IAAI,sBAAsB,GAAG,CAAC,CAAC;IAC/B,MAAM,mBAAmB,GAAa,EAAE,CAAC;IACzC,SAAS,CAAC,OAAO,CAAC,CAAC,QAAQ,EAAE,CAAC,EAAE,EAAE;QAChC,IAAI,CAAC,mBAAmB,CAAC,sBAAsB,CAAC,EAAE;YAChD,mBAAmB,CAAC,sBAAsB,CAAC,GAAG,QAAQ,GAAG,IAAI,CAAC;SAC/D;aAAM;YACL,mBAAmB,CAAC,sBAAsB,CAAC,IAAI,QAAQ,GAAG,IAAI,CAAC;SAChE;QACD,IAAI,CAAC,GAAG,yEAAS,CAAC,uBAAuB,KAAK,CAAC,EAAE;YAC/C,sBAAsB,EAAE,CAAC;SAC1B;IACH,CAAC,CAAC,CAAC;IACH,OAAO,mBAAmB,CAAC;AAC7B,CAAC;AAED;;;;GAIG;AACI,SAAS,qBAAqB,CAAC,OAAe;IACnD,MAAM,QAAQ,GAAG,YAAY,CAAC,OAAO,EAAE,KAAK,CAAC,CAAC;IAC9C,IAAI,QAAQ,GAAG,yEAAS,CAAC,aAAa,EAAE;QACtC,OAAO,OAAO,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,MAAM,CAAC,4BAA4B,CAAC,CAAC;KACjE;IACD,MAAM,SAAS,GAAG,OAAO,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;IACrC,OAAO,4BAA4B,CAAC,SAAS,CAAC,CAAC,MAAM,CAAC,4BAA4B,CAAC,CAAC;AACtF,CAAC;AAEM,SAAe,uBAAuB,CAAC,GAAW;;QACvD,MAAM,QAAQ,GAAG,MAAM,iDAAK,CAAC,GAAG,CAAC,CAAC;QAClC,MAAM,IAAI,GAAG,MAAM,QAAQ,CAAC,MAAM,EAAE,CAAC;QACrC,MAAM,OAAO,GAAG,MAAM,gDAAG,CAAC,IAAI,CAAC,CAAC;QAChC,OAAO,qBAAqB,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IAC7C,CAAC;CAAA;;;;;;;;;;;;;;;;;AC1CiC;AAEoC;AACnC;AACE;AAErC,MAAM,SAAS,GAAG,IAAI,qDAAqB,EAAE,CAAC;AAE9C;;GAEG;AACH,SAAS,iBAAiB,CAAC,IAAY,EAAE,SAAiB;IACxD,MAAM,kBAAkB,GAAG,SAAS,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC;IACzD,MAAM,gBAAgB,GAAG,kBAAkB,CAAC,MAAM,CAChD,CAAC,IAAY,EAAE,aAAa,EAAE,EAAE;QAC9B,uDAAuD;QACvD,MAAM,QAAQ,GAAG,2DAA2B,CAAC,IAAI,EAAE,aAAa,CAAC,CAAC;QAClE,OAAO,IAAI,GAAG,CAAC,QAAQ,GAAG,sEAAO,CAAC,mBAAmB,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACxE,CAAC,EACD,CAAC,CACF,CAAC;IACF,OAAO,gBAAgB,CAAC;AAC1B,CAAC;AAED,SAAS,kBAAkB,CAAC,KAAe,EAAE,SAAiB;IAC5D,OAAO,KAAK;SACT,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,iBAAiB,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC;SACjD,MAAM,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,EAAE,CAAC,KAAK,GAAG,KAAK,EAAE,CAAC,CAAC,CAAC;AAChD,CAAC;AAED;;;GAGG;AACH,SAAS,YAAY,CAAC,SAAiB,EAAE,oBAA4B;IACnE,MAAM,UAAU,GAAG,SAAS,GAAG,iFAAkB,CAAC,aAAa,CAAC;IAChE,MAAM,iBAAiB,GACrB,oBAAoB,GAAG,iFAAkB,CAAC,oBAAoB,CAAC;IACjE,OAAO,iBAAiB,GAAG,UAAU,CAAC;AACxC,CAAC;AAED,SAAS,UAAU,CAAC,KAAa;IAC/B,OAAO,qDAAqB,CAAC,eAAe,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;AAChE,CAAC;AAED,SAAS,iCAAiC,CACxC,SAAiB,EACjB,KAAa,EACb,aAAuB;IAEvB,MAAM,SAAS,GAAG,UAAU,CAAC,KAAK,CAAC,CAAC;IACpC,MAAM,aAAa,GAAG,UAAU,CAAC,SAAS,CAAC,CAAC;IAC5C,MAAM,gBAAgB,GAAG,kBAAkB,CAAC,aAAa,EAAE,aAAa,CAAC,CAAC;IAE1E,MAAM,gBAAgB,GAAG,YAAY,CACnC,iBAAiB,CAAC,SAAS,EAAE,aAAa,CAAC,EAC3C,gBAAgB,CACjB,CAAC;IACF,OAAO;QACL,IAAI,EAAE,SAAS;QACf,gBAAgB;KACjB,CAAC;AACJ,CAAC;AAED;;;;GAIG;AACH,SAAS,oCAAoC,CAC3C,SAAiB,EACjB,KAAa,EACb,aAAuB,EACvB,qBAAqB,GAAG,sEAAO,CAAC,0BAA0B;IAE1D,SAAS,6BAA6B,CAAC,CAAS,EAAE,CAAS;QACzD,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC;IACrC,CAAC;IACD,MAAM,SAAS,GAAG,SAAS,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;IACvC,yCAAyC;IACzC,IAAI,CAAC,SAAS,CAAC,SAAS,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE;QACpC,SAAS,CAAC,GAAG,EAAE,CAAC;KACjB;IACD,MAAM,SAAS,GAAG,iCAAiC,CACjD,SAAS,EACT,KAAK,EACL,aAAa,CACd,CAAC,gBAAgB,CAAC;IACnB,IAAI,YAAY,GAAG,SAAS,CAAC;IAC7B,IAAI,OAAO,GAAG,CAAC,CAAC;IAChB,IAAI,oBAAoB,GAAG,SAAS,CAAC,MAAM,CAAC;IAC5C,mEAAmE;IACnE,2FAA2F;IAC3F,OACE,6BAA6B,CAAC,SAAS,EAAE,YAAY,CAAC;QACpD,qBAAqB,GAAG,CAAC;QAC3B,OAAO,IAAI,oBAAoB,EAC/B;QACA,YAAY,GAAG,iCAAiC,CAC9C,SAAS,CAAC,KAAK,CAAC,OAAO,EAAE,oBAAoB,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EACxD,KAAK,EACL,aAAa,CACd,CAAC,gBAAgB,CAAC;QACnB,OAAO,EAAE,CAAC;KACX;IACD,6DAA6D;IAC7D,+EAA+E;IAC/E,OACE,6BAA6B,CAAC,SAAS,EAAE,YAAY,CAAC;QACpD,qBAAqB;QACvB,OAAO,IAAI,oBAAoB,EAC/B;QACA,YAAY,GAAG,iCAAiC,CAC9C,SAAS,CAAC,KAAK,CAAC,OAAO,EAAE,oBAAoB,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EACxD,KAAK,EACL,aAAa,CACd,CAAC,gBAAgB,CAAC;QACnB,oBAAoB,EAAE,CAAC;KACxB;IACD,kFAAkF;IAClF,0FAA0F;IAC1F,gBAAgB;IAChB,oBAAoB;QAClB,oBAAoB,GAAG,SAAS,CAAC,MAAM;YACrC,CAAC,CAAC,oBAAoB,GAAG,CAAC;YAC1B,CAAC,CAAC,oBAAoB,CAAC;IAC3B,OAAO;QACL,gBAAgB,EAAE,YAAY;QAC9B,IAAI,EAAE,SAAS,CAAC,KAAK,CAAC,OAAO,EAAE,oBAAoB,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC;KAC/D,CAAC;AACJ,CAAC;AAEM,SAAe,eAAe,CACnC,WAA8B;;QAE9B,OAAO,CAAC,IAAI,CACV,uBAAuB,WAAW,CAAC,KAAK,aAAa,WAAW,CAAC,oBAAoB,EAAE,CACxF,CAAC;QAEF,MAAM,EAAE,GAAG,WAAW,CAAC,MAAM,CAAC;QAC9B,IAAI,EAAE,KAAK,2EAAU,CAAC,UAAU,EAAE;YAChC,MAAM,MAAM,GAAG,+DAAuB,CAAC;YACvC,OAAO,CAAC,MAAM,MAAM,CAAC,OAAO,CAAC,WAAW,CAAC,oBAAoB,EAAE;gBAC7D,iBAAiB,EAAE,WAAW;gBAC9B,mBAAmB,EAAE,oCAAoC;aACtC,CAAC,CAAkB,CAAC;SAC1C;aAAM,IAAI,EAAE,KAAK,2EAAU,CAAC,KAAK,EAAE;YAClC,MAAM,MAAM,GAAG,2DAAmB,CAAC;YACnC,OAAO,CAAC,MAAM,MAAM,CAAC,OAAO,CAAC,WAAW,CAAC,oBAAoB,EAAE;gBAC7D,iBAAiB,EAAE,WAAW;gBAC9B,mBAAmB,EAAE,oCAAoC;aAC1C,CAAC,CAAkB,CAAC;SACtC;QAED,MAAM,MAAM,GAAG,+DAAuB,CAAC;QACvC,OAAO,CAAC,MAAM,MAAM,CAAC,OAAO,CAAC,WAAW,CAAC,oBAAoB,EAAE;YAC7D,iBAAiB,EAAE,WAAW;YAC9B,mBAAmB,EAAE,oCAAoC;SACtC,CAAC,CAAkB,CAAC;IAC3C,CAAC;CAAA;;;;;;;;ACvKD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAmC;AACO;AACb;AAEM;AAEnC,MAAM,GAAG,GAAG,oCAAO,EAAE,CAAC;AACtB,GAAG,CAAC,GAAG,CACL,iCAAI,CAAC;IACH,MAAM,EAAE;QACN,uBAAuB;QACvB,GAAG;QACH,uBAAuB;QACvB,6BAA6B;QAC7B,+BAA+B;KAChC;CACF,CAAC,CACH,CAAC;AACF,GAAG,CAAC,GAAG,CAAC,gDAAe,EAAE,CAAC,CAAC;AAC3B,GAAG,CAAC,GAAG,CAAC,sDAAqB,CAAC,EAAE,QAAQ,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;AAEnD,GAAG,CAAC,GAAG,CAAC,MAAM,EAAE,4DAAM,CAAC,CAAC;AAET,4DAAG,EAAC;;;;;;;ACvBnB,iC;;;;;;;ACAA;AAAA;AAAA;AAAmC;AACC;AAEpC,MAAM,MAAM,GAAG,8CAAc,EAAE,CAAC;AAEhC,MAAM,CAAC,GAAG,CAAC,SAAS,EAAE,uDAAY,CAAC,CAAC;AAErB,+DAAM,EAAC;;;;;;;;;;;;;;ACPa;AACQ;AAG3C,MAAM,MAAM,GAAG,8CAAc,EAAE,CAAC;AAEhC;;;;;;GAMG;AACH,MAAM,CAAC,GAAG,CACR,GAAG,EACH,CACE,GAAoB,EACpB,GAAqB,EACrB,IAA0B,EAC1B,EAAE,CAAC;IACH,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAW,CAAC;IACpC,MAAM,OAAO,GAAG,MAAM,sEAAgB,CACpC,KAAK;IACL,kDAAkD;IAClD;QACE,gBAAgB,EAAE,QAAQ,CAAC,GAAG,CAAC,KAAK,CAAC,gBAA0B,CAAC;QAChE,qBAAqB,EAAE,QAAQ,CAC7B,GAAG,CAAC,KAAK,CAAC,qBAA+B,CAC1C;KACF,CACF,CAAC;IACF,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;AAChC,CAAC,EACF,CAAC;AAEa,+DAAM,EAAC;;;;;;;;ACnCtB;AAAA;AAAA;AAAwB;;;;;;;;ACAxB;AAAA;AAAA;AAAsB;;;;;;;;ACAtB;AAAA;AAAA;AAAoC;;;;;;;ACApC,iC;;;;;;ACAA,oC;;;;;;;ACAA;AAAA;AAAA;AAAsB;;;;;;;ACAtB,oC;;;;;;;ACAA;AAAA;AAAA;AAAmC;;;;;;;ACAnC,sC;;;;;;;;;;;;;;ACAA;AAAA;AAA2B;AAE3B,MAAM,IAAI,GAAG,OAAO,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,CAAC;AACtC,MAAM,MAAM,GAAG,wDAAG,CAAC,MAAM,CAAC,IAAI,EAAE,GAAG,EAAE;IACnC,OAAO,CAAC,IAAI,CAAC,iCAAiC,IAAI,MAAM,CAAC,CAAC;AAC5D,CAAC,CAAC,CAAC;AACH,MAAM,CAAC,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,KAAK,CAAC,CAAC","file":"main.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 40);\n","module.exports = require(\"tslib\");","export * from './lib/interfaces';\n","module.exports = require(\"express\");","module.exports = require(\"node-fetch\");","export * from './europepmc-parser';\nexport * from './arxiv-parser';\n","module.exports = require(\"natural\");","export const correlationWeights = {\n  querySynonymWordFreq: 0.5,\n  queryWordFreq: 1,\n};\n\nexport const cutOffs = {\n  minimumWordDistance: 0.85,\n  maintainScoreWithinPercent: 10,\n};\n","export * from './lib/scraper';\n","export * from './europepmc-parser';\nexport * from './arxiv-parser';\n","module.exports = require(\"xml2js\");","import {\n  ParsedArticleHead,\n  UrlWithTag,\n  ScholarsDB,\n} from '@foodmedicine/interfaces';\n// eslint-disable-next-line @nrwl/nx/enforce-module-boundaries\nimport { Scraper } from '@foodmedicine/scraper';\nimport { EuropePMCParser } from '../parsers';\n\n/**\n * Construct the google scholars url which will be scraped\n * @param pageSize - the number of articles to get\n */\nfunction createEuropePMCUrl(\n  query: string,\n  pageSize: number,\n  synonym = true\n): string {\n  return encodeURI(\n    `https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=${query}&synonym=${synonym}&pageSize=${pageSize}`\n  );\n}\n\nexport async function runEuropePMCScrapers(\n  query: string,\n  querySynonyms: string[],\n  pageSize: number\n): Promise<ParsedArticleHead[]> {\n  const queryUrl = createEuropePMCUrl(query, pageSize);\n  const remedyScraper = new Scraper<ParsedArticleHead>(EuropePMCParser, {\n    url: queryUrl,\n    tag: {\n      query,\n      querySynonyms,\n    },\n  } as UrlWithTag);\n\n  const articleHeads = await remedyScraper.run();\n  return articleHeads;\n}\n","export const constants = {\n  MIN_TAB_COUNT: 5,\n  SENTENCES_PER_PARAGRAPH: 5,\n  MIN_CHAR_COUNT_PER_PARAGRAPH: 20,\n};\n","module.exports = require(\"body-parser\");","import {\n  ParsedArticleHead,\n  UrlWithTag,\n  ScholarsDB,\n} from '@foodmedicine/interfaces';\n// eslint-disable-next-line @nrwl/nx/enforce-module-boundaries\nimport { Scraper } from '@foodmedicine/scraper';\nimport { ArxivParser } from '../parsers';\n\n/**\n * Construct the google scholars url which will be scraped\n * @param pageSize - the number of articles to get\n */\nfunction createArxivUrl(\n  query: string,\n  pageSize: number,\n): string {\n  return encodeURI(\n    `http://export.arxiv.org/api/query?search_query=all:${query}&start=0&max_results=${pageSize}`\n  );\n}\n\nexport async function runArxivScrapers(\n  query: string,\n  querySynonyms: string[],\n  pageSize: number\n): Promise<ParsedArticleHead[]> {\n  const queryUrl = createArxivUrl(query, pageSize);\n  const remedyScraper = new Scraper<ParsedArticleHead>(ArxivParser, {\n    url: queryUrl,\n    tag: {\n      query,\n      querySynonyms,\n    },\n  } as UrlWithTag);\n\n  const articleHeads = await remedyScraper.run();\n  return articleHeads;\n}\n","import {\n  ParsedArticleParagraphStandalone,\n  ParsedArticle,\n  ParsedArticleParagraph,\n  ScholarsDB,\n} from '@foodmedicine/interfaces';\nimport { runScholarsScraper } from '@foodmedicine/scholars-scraper';\nimport * as articleParser from '@foodmedicine/article-parser';\n\nexport async function findQueryResults(\n  query: string,\n  opts?: {\n    numberOfArticles?: number;\n    maxNumberOfParagraphs?: number;\n  }\n): Promise<ParsedArticleParagraphStandalone[]> {\n  const articleHeads = await runScholarsScraper(\n    query,\n    ScholarsDB.RUN_ALL,\n    opts?.numberOfArticles || 25\n  );\n  const downloadProms: Promise<ParsedArticle>[] = articleHeads.map(\n    async (articleHead) => {\n      const evaluatedArticle: ParsedArticle = await articleParser.evaluateArticle(\n        articleHead\n      );\n      return evaluatedArticle;\n    }\n  );\n  const allEvaluatedArticles: ParsedArticle[] = await Promise.all(\n    downloadProms\n  );\n  const allParagraphsStandalone: ParsedArticleParagraphStandalone[] = [];\n  // For each evaluated article paragraph, form the ParsedArticleParagraphStandalone and push\n  // it to the array of all parsed article paragraphs\n  allEvaluatedArticles.forEach((article) => {\n    const standaloneParagraphs: ParsedArticleParagraphStandalone[] = article.paragraphs.map(\n      (paragraph: ParsedArticleParagraph) => {\n        return {\n          head: article.head,\n          ...paragraph,\n        };\n      }\n    );\n    allParagraphsStandalone.push(...standaloneParagraphs);\n  });\n  // Sort in descending order and remove empty items\n  allParagraphsStandalone.sort(\n    (a, b) => b.correlationScore - a.correlationScore\n  );\n  const allParagraphsStandaloneFiltered = allParagraphsStandalone.filter(\n    (paragraph) => paragraph.body?.trim().length > 0\n  );\n  return allParagraphsStandaloneFiltered.slice(\n    0,\n    opts?.maxNumberOfParagraphs || allParagraphsStandalone.length\n  );\n}\n","type getCorrelationScoreFunction = (\n  paragraph: string,\n  query: string,\n  querySynonyms: string[],\n  maintainWithinPercent?: number\n) => ParsedArticleParagraph;\n\nexport interface BaseParserOptions {\n  tag?: string;\n}\n\ninterface ArticleParserOptions extends BaseParserOptions {\n  getCorrelationScore: getCorrelationScoreFunction;\n  parsedArticleHead: ParsedArticleHead;\n}\n\nexport type ArxivOptions = ArticleParserOptions;\nexport type EuropePMCOptions = ArticleParserOptions;\n\n/**\n * Contains the outline information of an article\n */\nexport interface ParsedArticleHead {\n  DBType: ScholarsDB;\n  id: string;\n  title: string;\n  fullTextDownloadLink: string;\n  query: string;\n  querySynonyms?: string[];\n}\n\nexport interface ParsedArticle {\n  head: ParsedArticleHead;\n  paragraphs: ParsedArticleParagraph[];\n}\n\nexport interface ParsedArticleParagraph {\n  body: string;\n  correlationScore: number;\n}\n\nexport interface ParsedArticleParagraphStandalone\n  extends ParsedArticleParagraph {\n  head: ParsedArticleHead;\n}\n\nexport interface Parser<IRet> {\n  parserF: (inputSource: string, opts?: any) => Promise<IRet[] | IRet>;\n}\n\nexport enum ScholarsDB {\n  RUN_ALL = 0,\n  ARXIV,\n  EUROPE_PMC,\n}\n\nexport interface ScholarsParserOpts extends UrlWithTag {\n  tag: {\n    query: string;\n    querySynonyms: string[];\n  };\n}\n\nexport interface UrlWithTag {\n  url: string;\n  tag?: any;\n}\n","export * from './scraper/scholars-scraper';\n","import { ParsedArticleHead, ScholarsDB } from '@foodmedicine/interfaces';\nimport { runEuropePMCScrapers } from './europepmc-scraper';\nimport { runArxivScrapers } from './arxiv-scraper';\n\nimport { getSynonyms } from '@foodmedicine/word-explorer';\n/**\n * Find all the PDF urls which could have related articles to the remedy\n * @returns an array of PDF urls\n */\nexport async function runScholarsScraper(\n  query: string,\n  db: ScholarsDB,\n  pageSize: number\n): Promise<ParsedArticleHead[]> {\n  const querySynonyms = await getSynonyms(query);\n  if (db === ScholarsDB.RUN_ALL) {\n    // TODO have more intelligent partitioning of pageSize. If a search is more bio related, have there be more weight\n    // for europepmc. If more computer related, more arxiv weight\n    const europepmcProm = runEuropePMCScrapers(query, querySynonyms, Math.ceil(pageSize / 2));\n    const arxivProm = runArxivScrapers(query, querySynonyms, Math.ceil(pageSize / 2));\n    const articlesNested = Promise.all([europepmcProm, arxivProm]);\n    return (await articlesNested).flat();\n  } else if (db === ScholarsDB.EUROPE_PMC) {\n    return runEuropePMCScrapers(query, querySynonyms, pageSize);\n  } else if (db === ScholarsDB.ARXIV) {\n    return runArxivScrapers(query, querySynonyms, pageSize);\n  }\n  return runEuropePMCScrapers(query, querySynonyms, pageSize);\n}\n","import { Parser, UrlWithTag } from '@foodmedicine/interfaces';\nimport fetch from 'node-fetch';\nimport { parse } from 'querystring';\n\n/**\n * A generalized scraper abstraction class\n * This class can scrape different sites of pdfs\n * @param IRet - is the return interface for a scraped site or article\n */\nexport class Scraper<IRet> {\n  private urlsWithTags: UrlWithTag[];\n  private parser: Parser<IRet>;\n  constructor(parser: Parser<IRet>, ...urlsWithTags: UrlWithTag[]) {\n    this.parser = parser;\n    this.urlsWithTags = urlsWithTags;\n  }\n\n  /**\n   * Retrieves the source code of a url\n   */\n  async getSiteSource(url: string): Promise<string> {\n    const ret = await fetch(url);\n    return await ret.text();\n  }\n\n  async scrapeSiteSinglePage(url: string, opts: any): Promise<IRet[]> {\n    console.info(\"Scraping for\", url)\n    const source = await this.getSiteSource(url);\n    return await this.parser.parserF(source, opts) as IRet[];\n  }\n\n  /**\n   * Run the scraper for the inputed websites\n   */\n  public async run(): Promise<IRet[]> {\n    // create an array of promises to concurrently perform web scraping\n    const pageScrapingProms = this.urlsWithTags.map(async (urlWithTag) =>\n      await this.scrapeSiteSinglePage(urlWithTag.url, {\n        tag: urlWithTag.tag,\n      })\n    );\n    const scrapedRes = await Promise.all(pageScrapingProms);\n\n    // Because each individual page returns an array of results,\n    // results will be an array of arrays which should be flattened\n    return scrapedRes.flat();\n  }\n}\n","import {\n  Parser,\n  ParsedArticleHead,\n  ScholarsParserOpts,\n  ScholarsDB,\n} from '@foodmedicine/interfaces';\nimport * as xmlJs from 'xml2js';\n\n/**\n * A parser for https://www.ebi.ac.uk/europepmc/webservices/rest/\n */\nexport const EuropePMCParser: Parser<ParsedArticleHead> = {\n  parserF: async (xml, opts?: ScholarsParserOpts) => {\n    if (!opts) {\n      throw 'Options must be passed into this scraper';\n    }\n    const parser = new xmlJs.Parser();\n    const jsonRes = await parser.parseStringPromise(xml);\n    const allResults = jsonRes.responseWrapper.resultList[0].result;\n    const parsedHeads: ParsedArticleHead[] = allResults.map((res) => {\n      return {\n        id: res.id[0],\n        title: res.title[0],\n        fullTextDownloadLink: `https://www.ebi.ac.uk/europepmc/webservices/rest/${res.id[0]}/fullTextXML`,\n        query: opts.tag.query,\n        querySynonyms: opts.tag.querySynonyms,\n        DBType: ScholarsDB.EUROPE_PMC\n      };\n    });\n    return parsedHeads;\n  },\n};\n","import {\n  Parser,\n  ParsedArticleHead,\n  ScholarsParserOpts,\n  ScholarsDB,\n} from '@foodmedicine/interfaces';\nimport * as xmlJs from 'xml2js';\n\n/**\n * A parser for http://export.arxiv.org/api/query\n */\nexport const ArxivParser: Parser<ParsedArticleHead> = {\n  parserF: async (xml, opts?: ScholarsParserOpts) => {\n    if (!opts) {\n      throw 'Options must be passed into this scraper';\n    }\n    const parser = new xmlJs.Parser();\n    const jsonRes = await parser.parseStringPromise(xml);\n    const allResults = jsonRes.feed.entry || [];\n    const parsedHeads: ParsedArticleHead[] = allResults\n      .map((res) => {\n        const pdfDownloadLinks = res.link\n          .filter((linkItem) => linkItem.$.title === 'pdf')\n          .map((linkItem) => linkItem.$.href);\n        const fullTextDownloadLink = pdfDownloadLinks[0] || null;\n        return {\n          id: res.id,\n          title: res.title,\n          fullTextDownloadLink,\n          query: opts.tag.query,\n          querySynonyms: opts.tag.querySynonyms,\n          DBType: ScholarsDB.ARXIV,\n        };\n      })\n      .filter((parsedHead) => parsedHead.fullTextDownloadLink !== null);\n    return parsedHeads;\n  },\n};\n","import * as util from 'util';\nimport * as wordnet from 'wordnet';\nimport * as natural from 'natural';\n\nconst wordnetLookup = util.promisify(wordnet.lookup);\n\nexport async function getSynonyms(word: string): Promise<string[]> {\n  // n is for the nouns\n  const synonymWordsArrProms: Promise<string[][]>[] = word.split(' ').map(\n    async (individualWord): Promise<string[][]> => {\n      try {\n        return (\n          await wordnetLookup(natural.PorterStemmer.stem(individualWord))\n        ).map((def) => def.meta.words.map((item) => item.word));\n      } catch (e) {\n        console.error(\n          'Error finding synonyms for %s. Error %s',\n          individualWord,\n          e\n        );\n        return [[]];\n      }\n    }\n  );\n  const synonymWordsArr: string[][][] = await Promise.all(synonymWordsArrProms);\n  // make sure the items in the array are all truthy\n  const synonymWords = synonymWordsArr\n    .flat(Infinity)\n    .filter((synonym) => synonym && !word.includes(synonym));\n  if (!synonymWords) {\n    return [];\n  }\n  console.info('Found synonym words for %s:', word, synonymWords);\n  return synonymWords;\n}\n\n// TODO add glossary def to word meaning\n","export * from './parser';\nexport * from './correlation-score/correlation-score';\n","import {\n  ParsedArticle,\n  Parser,\n  ParsedArticleParagraph,\n  EuropePMCOptions,\n} from '@foodmedicine/interfaces';\nimport fetch from 'node-fetch'\nimport * as cheerio from 'cheerio';\n\nasync function downloadArticle(url: string): Promise<string> {\n  const ret = await fetch(url);\n  return await ret.text();\n}\n\n/**\n * A parser for https://www.ebi.ac.uk/europepmc/webservices/rest/\n */\nexport const EuropePMCParser: Parser<ParsedArticle> = {\n  parserF: async (xmlDownloadLink: string, opts?: EuropePMCOptions) => {\n    const xml = await downloadArticle(xmlDownloadLink);\n    if (!opts?.parsedArticleHead) {\n      throw 'Please add in the parsed head';\n    }\n    const $ = cheerio.load(xml);\n    const paragraphTexts: string[] = $('p')\n      .map((i, el) => $(el).text())\n      .get();\n    const paragraphs: ParsedArticleParagraph[] = paragraphTexts.map(\n      (paragraphText) =>\n        opts.getCorrelationScore(\n          paragraphText,\n          opts.parsedArticleHead.query,\n          opts.parsedArticleHead.querySynonyms\n        )\n    );\n    const article: ParsedArticle = {\n      head: opts.parsedArticleHead,\n      paragraphs,\n    };\n    return article;\n  },\n};\n","import {\n  ParsedArticle,\n  Parser,\n  ParsedArticleParagraph,\n  ArxivOptions,\n} from '@foodmedicine/interfaces';\nimport { getParagraphsFromPDFUrl } from '@foodmedicine/pdf-explorer';\n\n/**\n * A parser for https://www.ebi.ac.uk/europepmc/webservices/rest/\n */\nexport const ArxivParser: Parser<ParsedArticle> = {\n  parserF: async (fileUrl: string, opts?: ArxivOptions) => {\n    if (!opts?.parsedArticleHead) {\n      throw new Error('Please add in the parsed head');\n    }\n    const paragraphTexts = await getParagraphsFromPDFUrl(fileUrl);\n    try {\n      const paragraphs: ParsedArticleParagraph[] = paragraphTexts.map(\n        (paragraphText) =>\n          opts.getCorrelationScore(\n            paragraphText,\n            opts.parsedArticleHead.query,\n            opts.parsedArticleHead.querySynonyms\n          )\n      );\n      const article: ParsedArticle = {\n        head: opts.parsedArticleHead,\n        paragraphs,\n      };\n      return article;\n    } catch (e) {\n      console.error(\n        `Error parsing article from Arxiv. Skipping the article `,\n        e\n      );\n      return {\n        head: opts.parsedArticleHead,\n        paragraphs: [],\n      };\n    }\n  },\n};\n","import fetch from 'node-fetch';\nimport pdf from 'pdf-parse';\nimport { constants } from './pdf-explorer-constants';\n\n/**\n * Check whether the paragraphs contains valid information\n */\nfunction paragraphContainsInformation(body: string): boolean {\n  return body.length > constants.MIN_CHAR_COUNT_PER_PARAGRAPH && body.includes('.');\n}\n\nfunction getCharCount(text: string, pattern: RegExp): number {\n  return (text.match(pattern) || []).length;\n}\n\nfunction groupSentencesIntoParagraphs(sentences: string[]): string[] {\n  let syntheticParagraphsInd = 0;\n  const syntheticParagraphs: string[] = [];\n  sentences.forEach((sentence, i) => {\n    if (!syntheticParagraphs[syntheticParagraphsInd]) {\n      syntheticParagraphs[syntheticParagraphsInd] = sentence + '. ';\n    } else {\n      syntheticParagraphs[syntheticParagraphsInd] += sentence + '. ';\n    }\n    if (i % constants.SENTENCES_PER_PARAGRAPH === 0) {\n      syntheticParagraphsInd++;\n    }\n  });\n  return syntheticParagraphs;\n}\n\n/**\n * Split text into paragraph by first attempting to split by the tab character.\n * If the tab character does not appear more than {@code MIN_TAB_COUNT} number of times,\n * synthetically create paragraphs by grouping sentences together.\n */\nexport function splitTextToParagraphs(rawText: string): string[] {\n  const tabCount = getCharCount(rawText, /\\t/g);\n  if (tabCount > constants.MIN_TAB_COUNT) {\n    return rawText.split('\\t').filter(paragraphContainsInformation);\n  }\n  const sentences = rawText.split('.');\n  return groupSentencesIntoParagraphs(sentences).filter(paragraphContainsInformation);\n}\n\nexport async function getParagraphsFromPDFUrl(url: string): Promise<string[]> {\n  const fetchRes = await fetch(url);\n  const buff = await fetchRes.buffer();\n  const pdfData = await pdf(buff);\n  return splitTextToParagraphs(pdfData.text);\n}\n","import {\n  ParsedArticleHead,\n  Parser,\n  ParsedArticle,\n  ParsedArticleParagraph,\n  EuropePMCOptions,\n  ScholarsDB,\n  ArxivOptions,\n} from '@foodmedicine/interfaces';\nimport * as fetch from 'node-fetch';\nimport { correlationWeights, cutOffs } from './correlation-constants';\nimport * as natural from 'natural';\nimport * as parsers from '../parser';\n\nconst tokenizer = new natural.WordTokenizer();\n\n/**\n * Find word frequencies through fuzzy search\n */\nfunction findWordFreqFuzzy(word: string, paragraph: string): number {\n  const tokenizedParagraph = tokenizer.tokenize(paragraph);\n  const overallFreqScore = tokenizedParagraph.reduce(\n    (freq: number, paragraphWord) => {\n      // distance ranges from 0 to 1. 1 being a perfect match\n      const distance = natural.JaroWinklerDistance(word, paragraphWord);\n      return freq + (distance > cutOffs.minimumWordDistance ? distance : 0);\n    },\n    0\n  );\n  return overallFreqScore;\n}\n\nfunction findWordsFreqFuzzy(words: string[], paragraph: string): number {\n  return words\n    .map((word) => findWordFreqFuzzy(word, paragraph))\n    .reduce((total, score) => total + score, 0);\n}\n\n/**\n * Compute the correlation score based off of the inputs\n * Current features include query frequencies, query synonym frequencies\n */\nfunction computeScore(queryFreq: number, querySynonymWordFreq: number): number {\n  const queryScore = queryFreq * correlationWeights.queryWordFreq;\n  const querySynonymScore =\n    querySynonymWordFreq * correlationWeights.querySynonymWordFreq;\n  return querySynonymScore + queryScore;\n}\n\nfunction stemString(input: string) {\n  return natural.PorterStemmer.tokenizeAndStem(input).join(' ');\n}\n\nfunction getWholeParagraphCorrelationScore(\n  paragraph: string,\n  query: string,\n  querySynonyms: string[]\n): ParsedArticleParagraph {\n  const queryStem = stemString(query);\n  const paragraphStem = stemString(paragraph);\n  const querySynonymFreq = findWordsFreqFuzzy(querySynonyms, paragraphStem);\n\n  const correlationScore = computeScore(\n    findWordFreqFuzzy(queryStem, paragraphStem),\n    querySynonymFreq\n  );\n  return {\n    body: paragraph,\n    correlationScore,\n  };\n}\n\n/**\n * Get the correlation score for the segment of a paragraph with the most matches\n * Will shorten the paragraph as much as possible while trying to mantain the same correlation score\n * + or - {@code maintainWithinPercent}\n */\nfunction getShortestParagraphCorrelationScore(\n  paragraph: string,\n  query: string,\n  querySynonyms: string[],\n  maintainWithinPercent = cutOffs.maintainScoreWithinPercent\n): ParsedArticleParagraph {\n  function calculatePercentageDifference(x: number, y: number): number {\n    return Math.abs((x - y) / x) * 100;\n  }\n  const sentences = paragraph.split('.');\n  // remove the last element if it is empty\n  if (!sentences[sentences.length - 1]) {\n    sentences.pop();\n  }\n  const initScore = getWholeParagraphCorrelationScore(\n    paragraph,\n    query,\n    querySynonyms\n  ).correlationScore;\n  let currentScore = initScore;\n  let leftInd = 0;\n  let rightIndNonInclusive = sentences.length;\n  // Attempts to remove sentences from the beginning of the paragraph\n  // while having the correlation score stay within half of the {@code maintainWithinPercent}\n  while (\n    calculatePercentageDifference(initScore, currentScore) <=\n      maintainWithinPercent / 2 &&\n    leftInd != rightIndNonInclusive\n  ) {\n    currentScore = getWholeParagraphCorrelationScore(\n      sentences.slice(leftInd, rightIndNonInclusive).join('.'),\n      query,\n      querySynonyms\n    ).correlationScore;\n    leftInd++;\n  }\n  // Attempts to remove sentences from the end of the paragraph\n  // while having the correlation score stay within {@code maintainWithinPercent}\n  while (\n    calculatePercentageDifference(initScore, currentScore) <=\n      maintainWithinPercent &&\n    leftInd != rightIndNonInclusive\n  ) {\n    currentScore = getWholeParagraphCorrelationScore(\n      sentences.slice(leftInd, rightIndNonInclusive).join('.'),\n      query,\n      querySynonyms\n    ).correlationScore;\n    rightIndNonInclusive--;\n  }\n  // Increment {@code rightIndNonInclusive} because the new correlation score may be\n  // over the alloted percentage range after the prior loop. Thus, the last sentence removed\n  // is added back\n  rightIndNonInclusive =\n    rightIndNonInclusive < sentences.length\n      ? rightIndNonInclusive + 1\n      : rightIndNonInclusive;\n  return {\n    correlationScore: currentScore,\n    body: sentences.slice(leftInd, rightIndNonInclusive).join('.'),\n  };\n}\n\nexport async function evaluateArticle(\n  articleHead: ParsedArticleHead,\n): Promise<ParsedArticle> {\n  console.info(\n    `Downloaded data for ${articleHead.query} with url ${articleHead.fullTextDownloadLink}`\n  );\n\n  const db = articleHead.DBType;\n  if (db === ScholarsDB.EUROPE_PMC) {\n    const parser = parsers.EuropePMCParser;\n    return (await parser.parserF(articleHead.fullTextDownloadLink, {\n      parsedArticleHead: articleHead,\n      getCorrelationScore: getShortestParagraphCorrelationScore,\n    } as EuropePMCOptions)) as ParsedArticle;\n  } else if (db === ScholarsDB.ARXIV) {\n    const parser = parsers.ArxivParser;\n    return (await parser.parserF(articleHead.fullTextDownloadLink, {\n      parsedArticleHead: articleHead,\n      getCorrelationScore: getShortestParagraphCorrelationScore,\n    } as ArxivOptions)) as ParsedArticle;\n  }\n\n  const parser = parsers.EuropePMCParser;\n  return (await parser.parserF(articleHead.fullTextDownloadLink, {\n    parsedArticleHead: articleHead,\n    getCorrelationScore: getShortestParagraphCorrelationScore,\n  } as EuropePMCOptions)) as ParsedArticle;\n}\n","import * as express from 'express';\nimport * as bodyParser from 'body-parser';\nimport * as cors from 'cors';\n\nimport router from './controllers';\n\nconst app = express();\napp.use(\n  cors({\n    origin: [\n      'http://localhost:4200',\n      '*',\n      'https://*.netlify.app',\n      'https://schopal.netlify.app',\n      'https://schopal.neocities.org',\n    ],\n  })\n);\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: true }));\n\napp.use('/api', router);\n\nexport default app;\n","module.exports = require(\"cors\");","import * as express from 'express';\nimport searchRouter from './search';\n\nconst router = express.Router();\n\nrouter.use('/search', searchRouter);\n\nexport default router;\n","import * as express from 'express';\nimport { findQueryResults } from '../daos';\nimport { ScholarsDB } from '@foodmedicine/interfaces';\n\nconst router = express.Router();\n\n/**\n * Search the database for correlated paragraphs\n * @query q - query string\n * @query db - which db to use\n * @query maxNumberOfParagraphs - optional max number of paragraphs\n * @query numberOfArticles - optional number of articles to search\n */\nrouter.get(\n  '/',\n  async (\n    req: express.Request,\n    res: express.Response,\n    next: express.NextFunction\n  ) => {\n    const query = req.query.q as string;\n    const results = await findQueryResults(\n      query,\n      // parseInt(req.query.db as string) as ScholarsDB,\n      {\n        numberOfArticles: parseInt(req.query.numberOfArticles as string),\n        maxNumberOfParagraphs: parseInt(\n          req.query.maxNumberOfParagraphs as string\n        ),\n      }\n    );\n    res.status(200).json(results);\n  }\n);\n\nexport default router;\n","export * from './search'","export * from './lib';\n","export * from './lib/word-explorer';\n","module.exports = require(\"util\");","module.exports = require(\"wordnet\");","export * from './lib';\n","module.exports = require(\"cheerio\");","export * from './lib/pdf-explorer';\n","module.exports = require(\"pdf-parse\");","import app from './app/app'\n\nconst port = process.env.PORT || 3333;\nconst server = app.listen(port, () => {\n  console.info(`Listening at http://localhost:${port}/api`);\n});\nserver.on('error', console.error);\n"],"sourceRoot":""}